<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<title>nnengine: Network.cpp Source File</title>

<link href="tabs.css" rel="stylesheet" type="text/css"/>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { searchBox.OnSelectItem(0); });
</script>

</head>
<body>
<div id="top"><!-- do not remove this div! -->


<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  
  
  <td style="padding-left: 0.5em;">
   <div id="projectname">nnengine
   
   </div>
   
  </td>
  
  
  
 </tr>
 </tbody>
</table>
</div>

<!-- Generated by Doxygen 1.7.6.1 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li class="current"><a href="files.html"><span>Files</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
  <div id="navrow2" class="tabs2">
    <ul class="tablist">
      <li><a href="files.html"><span>File&#160;List</span></a></li>
      <li><a href="globals.html"><span>File&#160;Members</span></a></li>
    </ul>
  </div>
</div>
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
  initNavTree('_network_8cpp.html','');
</script>
<div id="doc-content">
<div class="header">
  <div class="headertitle">
<div class="title">Network.cpp</div>  </div>
</div><!--header-->
<div class="contents">
<a href="_network_8cpp.html">Go to the documentation of this file.</a><div class="fragment"><pre class="fragment"><a name="l00001"></a>00001 
<a name="l00002"></a>00002 <span class="comment">//    NETWORK.CPP - Neural network object </span>
<a name="l00003"></a>00003 <span class="comment">//            4/8/94 - RAB</span>
<a name="l00005"></a>00005 <span class="comment"></span><span class="preprocessor">#include &quot;<a class="code" href="_network_8h.html">Network.h</a>&quot;</span>
<a name="l00006"></a>00006 <span class="preprocessor">#include &quot;<a class="code" href="_text_8h.html">Text.h</a>&quot;</span>
<a name="l00007"></a>00007 <span class="preprocessor">#include &quot;<a class="code" href="_c_mindset_config_8h.html">CMindsetConfig.h</a>&quot;</span>
<a name="l00008"></a>00008 <span class="preprocessor">#include &quot;Crc32.h&quot;</span>
<a name="l00009"></a>00009 <span class="preprocessor">#include &lt;cstdio&gt;</span>
<a name="l00010"></a>00010 <span class="preprocessor">#include &lt;errno.h&gt;</span>
<a name="l00011"></a>00011 
<a name="l00012"></a>00012 <span class="comment">// Constructor</span>
<a name="l00013"></a>00013 
<a name="l00014"></a><a class="code" href="class_neural_net.html#a66b1ddd47bc5b393cf184f02517e82d4">00014</a> <a class="code" href="class_neural_net.html#a66b1ddd47bc5b393cf184f02517e82d4" title="Constructor.">NeuralNet::NeuralNet</a>()
<a name="l00015"></a>00015 {
<a name="l00016"></a>00016     <span class="comment">// Determinte the number of processors </span>
<a name="l00017"></a>00017     <a class="code" href="class_neural_net.html#ae3f57ff94e97b1b04f49787b58cf2f80" title="For internal use, this count includes bias units.">elements</a> = NULL;
<a name="l00018"></a>00018     <a class="code" href="class_neural_net.html#abeb6e703d60a6dbe3a979aa168d8ea1a" title="For external use.">pelements</a> = NULL;
<a name="l00019"></a>00019     <a class="code" href="class_neural_net.html#af2ba1bf36dda0676496d3f8a5c5cac52" title="Neuron layers.">PElement</a> = NULL;
<a name="l00020"></a>00020     <a class="code" href="class_neural_net.html#a864417aa22e18e9bb4fc14b1664b65ff" title="Creation flag.">bCreated</a> = <span class="keyword">false</span>;
<a name="l00021"></a>00021 };
<a name="l00022"></a>00022 
<a name="l00023"></a>00023 
<a name="l00025"></a>00025 <span class="comment">//     Create for NeuralNet</span>
<a name="l00026"></a>00026 <span class="comment">//</span>
<a name="l00027"></a>00027 <span class="comment">//     NOTE: Each neuron randomizes it&#39;s own weights when it is created</span>
<a name="l00028"></a>00028 <span class="comment">//</span>
<a name="l00029"></a>00029 
<a name="l00030"></a><a class="code" href="class_neural_net.html#a7ef3cb1725b52ec0b3b347c228fe131e">00030</a> <span class="keywordtype">int</span> <a class="code" href="class_neural_net.html#a7ef3cb1725b52ec0b3b347c228fe131e" title="Create the network from entered parameters.">NeuralNet::Create</a>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> num_layers, <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> *layer_elements, <span class="keywordtype">double</span> learn_rate,
<a name="l00031"></a>00031     <span class="keywordtype">double</span> allowable_error, <span class="keywordtype">double</span> momentum_factor, <span class="keywordtype">double</span> gain_f, <span class="keywordtype">bool</span> bRProp)
<a name="l00032"></a>00032 {
<a name="l00033"></a>00033     <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> element;
<a name="l00034"></a>00034     <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> uType;
<a name="l00035"></a>00035 
<a name="l00036"></a>00036     <span class="comment">// Load our elements array</span>
<a name="l00037"></a>00037     <a class="code" href="class_neural_net.html#ae3f57ff94e97b1b04f49787b58cf2f80" title="For internal use, this count includes bias units.">elements</a> = <span class="keyword">new</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span>[num_layers];
<a name="l00038"></a>00038     <a class="code" href="class_neural_net.html#abeb6e703d60a6dbe3a979aa168d8ea1a" title="For external use.">pelements</a> = <span class="keyword">new</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span>[num_layers];
<a name="l00039"></a>00039 
<a name="l00040"></a>00040     <span class="comment">// We need the gain loaded</span>
<a name="l00041"></a>00041     <a class="code" href="class_neural_net.html#a1d819b4e7babcd2149f3382afc675090" title="The gain.">dGain</a> = gain_f;
<a name="l00042"></a>00042 
<a name="l00043"></a>00043     ::memcpy(<a class="code" href="class_neural_net.html#ae3f57ff94e97b1b04f49787b58cf2f80" title="For internal use, this count includes bias units.">elements</a>, layer_elements, <span class="keyword">sizeof</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span>) * num_layers);
<a name="l00044"></a>00044     ::memcpy(<a class="code" href="class_neural_net.html#abeb6e703d60a6dbe3a979aa168d8ea1a" title="For external use.">pelements</a>, layer_elements, <span class="keyword">sizeof</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span>) * num_layers);
<a name="l00045"></a>00045 
<a name="l00046"></a>00046     <span class="comment">// If there is a bias, allocate extra neuron except in output</span>
<a name="l00047"></a>00047     <span class="keywordflow">for</span>(<a class="code" href="class_neural_net.html#a0e202814817d8acf923bbb8481a79e11" title="Number of layers.">layers</a> = 0; <a class="code" href="class_neural_net.html#a0e202814817d8acf923bbb8481a79e11" title="Number of layers.">layers</a> &lt; num_layers - 1; <a class="code" href="class_neural_net.html#a0e202814817d8acf923bbb8481a79e11" title="Number of layers.">layers</a>++)
<a name="l00048"></a>00048         <a class="code" href="class_neural_net.html#ae3f57ff94e97b1b04f49787b58cf2f80" title="For internal use, this count includes bias units.">elements</a>[<a class="code" href="class_neural_net.html#a0e202814817d8acf923bbb8481a79e11" title="Number of layers.">layers</a>]++;
<a name="l00049"></a>00049 
<a name="l00050"></a>00050     <span class="comment">// Create the neurons</span>
<a name="l00051"></a>00051     <a class="code" href="class_neural_net.html#aacf7b9fc4847f56880583b2a3d647b01" title="Total connections (including BIAS units)">lTotalConnects</a> = 0;
<a name="l00052"></a>00052     <a class="code" href="class_neural_net.html#af2ba1bf36dda0676496d3f8a5c5cac52" title="Neuron layers.">PElement</a> = <span class="keyword">new</span> <a class="code" href="class_neuron.html">Neuron</a>**[num_layers]; <span class="comment">// Allocate layer pointers</span>
<a name="l00053"></a>00053     <span class="keywordflow">for</span>(<a class="code" href="class_neural_net.html#a0e202814817d8acf923bbb8481a79e11" title="Number of layers.">layers</a> = 0; <a class="code" href="class_neural_net.html#a0e202814817d8acf923bbb8481a79e11" title="Number of layers.">layers</a> &lt; num_layers; <a class="code" href="class_neural_net.html#a0e202814817d8acf923bbb8481a79e11" title="Number of layers.">layers</a>++)
<a name="l00054"></a>00054     { <span class="comment">// Allocate neuron pointer</span>
<a name="l00055"></a>00055         <span class="keywordflow">if</span> (<a class="code" href="class_neural_net.html#a0e202814817d8acf923bbb8481a79e11" title="Number of layers.">layers</a>)
<a name="l00056"></a>00056             <a class="code" href="class_neural_net.html#aacf7b9fc4847f56880583b2a3d647b01" title="Total connections (including BIAS units)">lTotalConnects</a> += (long) (<a class="code" href="class_neural_net.html#ae3f57ff94e97b1b04f49787b58cf2f80" title="For internal use, this count includes bias units.">elements</a>[<a class="code" href="class_neural_net.html#a0e202814817d8acf923bbb8481a79e11" title="Number of layers.">layers</a> - 1] * <a class="code" href="class_neural_net.html#ae3f57ff94e97b1b04f49787b58cf2f80" title="For internal use, this count includes bias units.">elements</a>[<a class="code" href="class_neural_net.html#a0e202814817d8acf923bbb8481a79e11" title="Number of layers.">layers</a>]);
<a name="l00057"></a>00057         <a class="code" href="class_neural_net.html#af2ba1bf36dda0676496d3f8a5c5cac52" title="Neuron layers.">PElement</a>[<a class="code" href="class_neural_net.html#a0e202814817d8acf923bbb8481a79e11" title="Number of layers.">layers</a>] = <span class="keyword">new</span> <a class="code" href="class_neuron.html">Neuron</a>*[<a class="code" href="class_neural_net.html#ae3f57ff94e97b1b04f49787b58cf2f80" title="For internal use, this count includes bias units.">elements</a>[<a class="code" href="class_neural_net.html#a0e202814817d8acf923bbb8481a79e11" title="Number of layers.">layers</a>]];
<a name="l00058"></a>00058 
<a name="l00059"></a>00059         <span class="comment">// Set our layer enum</span>
<a name="l00060"></a>00060         <span class="keywordflow">if</span> (!layers)
<a name="l00061"></a>00061         {
<a name="l00062"></a>00062             uType = <a class="code" href="class_neural_net.html#a8243ba142eead5765e0959f57d1747f3a877f4f35bb41b96f3839ea421c35c353" title="Identify the layer a neuron belongs to.">INPUT</a>;
<a name="l00063"></a>00063             <a class="code" href="class_neural_net.html#aaa5c40b8b83fdd61da09693e7f5d1132" title="Number of inputs in input layer.">num_inputs</a> = 1;
<a name="l00064"></a>00064         }
<a name="l00065"></a>00065         <span class="keywordflow">else</span>
<a name="l00066"></a>00066         {
<a name="l00067"></a>00067             <a class="code" href="class_neural_net.html#aaa5c40b8b83fdd61da09693e7f5d1132" title="Number of inputs in input layer.">num_inputs</a> = elements[layers - 1];
<a name="l00068"></a>00068             <span class="keywordflow">if</span> (layers == num_layers - 1)
<a name="l00069"></a>00069                 uType = <a class="code" href="class_neural_net.html#a8243ba142eead5765e0959f57d1747f3aa2b0cbc10f8b696b6f419109e7fac591">OUTPUT</a>;
<a name="l00070"></a>00070             <span class="keywordflow">else</span>
<a name="l00071"></a>00071                 uType = <a class="code" href="class_neural_net.html#a8243ba142eead5765e0959f57d1747f3a2e11150086e6ef07cc27868536c2edd0">HIDDEN</a>;
<a name="l00072"></a>00072         };
<a name="l00073"></a>00073 
<a name="l00074"></a>00074         <span class="comment">// Network is &quot;massively connected&quot;, </span>
<a name="l00075"></a>00075         <span class="comment">// all previous PEs -&gt; this layer</span>
<a name="l00076"></a>00076         <span class="keywordflow">for</span>(element = 0; element &lt; elements[<a class="code" href="class_neural_net.html#a0e202814817d8acf923bbb8481a79e11" title="Number of layers.">layers</a>]; element++)
<a name="l00077"></a>00077         {
<a name="l00078"></a>00078             <a class="code" href="class_neural_net.html#af2ba1bf36dda0676496d3f8a5c5cac52" title="Neuron layers.">PElement</a>[<a class="code" href="class_neural_net.html#a0e202814817d8acf923bbb8481a79e11" title="Number of layers.">layers</a>][element] = <a class="code" href="class_neural_net.html#a6b997859c3d6c4918a19901f6be27e84" title="This allows a derived class to have NeuralNet allocate a derived Neuron.">AllocateNeuron</a>(<span class="keyword">this</span>, <a class="code" href="class_neural_net.html#aaa5c40b8b83fdd61da09693e7f5d1132" title="Number of inputs in input layer.">num_inputs</a>, element, uType);
<a name="l00079"></a>00079         };
<a name="l00080"></a>00080     };
<a name="l00081"></a>00081 
<a name="l00082"></a>00082     <a class="code" href="class_neural_net.html#a0e202814817d8acf923bbb8481a79e11" title="Number of layers.">layers</a> = num_layers;
<a name="l00083"></a>00083     <a class="code" href="class_neural_net.html#af3c63ff1bfa0968e10ee9a894b45ae2e" title="Shortcut which is equal (layers - 1)">sublayer</a> = <a class="code" href="class_neural_net.html#a0e202814817d8acf923bbb8481a79e11" title="Number of layers.">layers</a> - 1;
<a name="l00084"></a>00084     <a class="code" href="class_neural_net.html#a32c7a3ced047c1d71e99f2c4b51dc14e" title="Allowable error.">error</a> = allowable_error;
<a name="l00085"></a>00085     <a class="code" href="class_neural_net.html#a47b081356cece6d51cda1d9a546cf53c" title="Learn rate.">delta</a> = learn_rate;
<a name="l00086"></a>00086     <a class="code" href="class_neural_net.html#ae2abb290d0c972e07df4a6b8ba37a910" title="Momentum factor.">momentum</a> = momentum_factor;
<a name="l00087"></a>00087     <a class="code" href="class_neural_net.html#a13b37e7743c5b0907c3106a50f4462c7" title="For adjustable learning rate.">prev_error</a> = <a class="code" href="class_neural_net.html#a46892982146f371e2a2776f4a167d071" title="The lowest error we&#39;ve achieved.">dLowestError</a> = <a class="code" href="_network_8h.html#a6b65f4b50d2d129e2fe16f8febc172c4">MAX_DOUBLE</a>; <span class="comment">// Some ridiculously high number </span>
<a name="l00088"></a>00088     <a class="code" href="class_neural_net.html#a3d8aa2fd8788831b334b8fbf5cec26b4" title="Total error.">total_error</a> = <a class="code" href="class_neural_net.html#a848726a24e8f86db49a6a2ec54624b7b" title="Saved total error during training for status display.">fErrorDisplay</a> = 0.0f;
<a name="l00089"></a>00089     <a class="code" href="class_neural_net.html#ade1f7df3aff13a38ef212ce990774c57" title="Is the net trained.">iTrained</a> = <a class="code" href="_network_8h.html#acc6eb0226fb009b2e6bf244c4aed3909">UNTRAINED</a>;
<a name="l00090"></a>00090     <a class="code" href="class_neural_net.html#a2275579cdf93de684e32e4d2cfb7b3e4" title="How many iterations during training.">lIteration</a> = 0;
<a name="l00091"></a>00091     <a class="code" href="class_neural_net.html#a8e224c79e2b0bb43b9fa3a3e134247b2" title="Total elapsed time.">dwTotalElapsed</a> = 0;
<a name="l00092"></a>00092     <a class="code" href="class_neural_net.html#a6e200122a6165c503741b9d54b735e22" title="Use the RProp algorithm for training.">bUseRProp</a> = bRProp;
<a name="l00093"></a>00093 
<a name="l00094"></a>00094     <span class="comment">// If there is a bias, set the last one on the first layer</span>
<a name="l00095"></a>00095     <a class="code" href="class_neural_net.html#af2ba1bf36dda0676496d3f8a5c5cac52" title="Neuron layers.">PElement</a>[0][<a class="code" href="class_neural_net.html#ae3f57ff94e97b1b04f49787b58cf2f80" title="For internal use, this count includes bias units.">elements</a>[0] - 1]-&gt;<a class="code" href="class_neuron.html#ab1583b0659eb2189fe0fd20b4af2ddb3" title="Actual output.">output</a> = 1.0f;
<a name="l00096"></a>00096 
<a name="l00097"></a>00097     <span class="comment">// Randomize the weights</span>
<a name="l00098"></a>00098     <a class="code" href="class_neural_net.html#a774147214019e55daae829a66af75657" title="Set all inputs in preparation for learning.">RandomizeWeights</a>();
<a name="l00099"></a>00099     <a class="code" href="class_neural_net.html#a864417aa22e18e9bb4fc14b1664b65ff" title="Creation flag.">bCreated</a> = <span class="keyword">true</span>;
<a name="l00100"></a>00100 
<a name="l00101"></a>00101     <span class="keywordflow">return</span>(0);
<a name="l00102"></a>00102 };
<a name="l00104"></a>00104 
<a name="l00105"></a>00105 
<a name="l00106"></a>00106 
<a name="l00108"></a>00108 <span class="comment">//  Create a NeuralNet from a saved network file.  This will include saved weights.</span>
<a name="l00109"></a>00109 <span class="comment">//</span>
<a name="l00110"></a>00110 <span class="comment">//  Each neuron randomizes it&#39;s own weights when it is created, but after</span>
<a name="l00111"></a>00111 <span class="comment">//  allocation, we will set them based on values in the file. </span>
<a name="l00112"></a>00112 <span class="comment">//</span>
<a name="l00113"></a>00113 
<a name="l00114"></a><a class="code" href="class_neural_net.html#a9889958ef1143b8c2352c8eed4b3dab4">00114</a> <span class="keywordtype">int</span> <a class="code" href="class_neural_net.html#a7ef3cb1725b52ec0b3b347c228fe131e" title="Create the network from entered parameters.">NeuralNet::Create</a>(<span class="keyword">const</span> <span class="keywordtype">char</span> * szNetworkFile)
<a name="l00115"></a>00115 {
<a name="l00116"></a>00116     <a class="code" href="class_c_mindset_config.html">CMindsetConfig</a> cConfig;
<a name="l00117"></a>00117     <span class="keywordtype">int</span> iReturn;
<a name="l00118"></a>00118     <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> layer;
<a name="l00119"></a>00119     <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> pe;
<a name="l00120"></a>00120     <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> input;
<a name="l00121"></a>00121     <span class="keywordtype">int</span> iWeightCount = 0;
<a name="l00122"></a>00122     <span class="keywordtype">int</span> iLabel = 0;
<a name="l00123"></a>00123 
<a name="l00124"></a>00124     <a class="code" href="class_neural_net.html#afba7d7171f02df7c5ecc7dc992bdc0a9" title="If created using parse XML.">bVerified</a> = <span class="keyword">false</span>;
<a name="l00125"></a>00125     iReturn = cConfig.<a class="code" href="class_c_mindset_config.html#af2e2e92ab50d9b8c3c0b1671b9911db4">ParseXMLFile</a>(szNetworkFile);
<a name="l00126"></a>00126     <span class="keywordflow">if</span> (iReturn)
<a name="l00127"></a>00127         <span class="keywordflow">return</span>(iReturn);
<a name="l00128"></a>00128     <a class="code" href="class_neural_net.html#afba7d7171f02df7c5ecc7dc992bdc0a9" title="If created using parse XML.">bVerified</a> = cConfig.<a class="code" href="class_c_mindset_config.html#a8947a4885d913d0ec2e6933ca7a94e32">bVerified</a>;
<a name="l00129"></a>00129     <span class="keywordflow">if</span> (!<a class="code" href="class_neural_net.html#afba7d7171f02df7c5ecc7dc992bdc0a9" title="If created using parse XML.">bVerified</a>)
<a name="l00130"></a>00130         <span class="keywordflow">return</span>(-1);
<a name="l00131"></a>00131 
<a name="l00132"></a>00132     <span class="comment">// Create the network</span>
<a name="l00133"></a>00133     <a class="code" href="class_neural_net.html#a7ef3cb1725b52ec0b3b347c228fe131e" title="Create the network from entered parameters.">Create</a>(cConfig.<a class="code" href="class_c_mindset_config.html#a0a0ab477880c7e58afaee94473c44416">iLayers</a>,
<a name="l00134"></a>00134         (<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> *) &amp;(cConfig.<a class="code" href="class_c_mindset_config.html#aa841ad3a43a67707baa4413320be5bea">vLayerNodeCount</a>[0]),
<a name="l00135"></a>00135         cConfig.<a class="code" href="class_c_mindset_config.html#a3e852a2892e0bbb78a3e37178e20aed9">dLearnRate</a>,
<a name="l00136"></a>00136         cConfig.<a class="code" href="class_c_mindset_config.html#aa89a9db7f7ab4ba88b78a69d1fd74a41">dAllowableError</a>,
<a name="l00137"></a>00137         cConfig.<a class="code" href="class_c_mindset_config.html#a936a323574087e5c3fe57ab5c2ec0bb1">dMomentum</a>,
<a name="l00138"></a>00138         cConfig.<a class="code" href="class_c_mindset_config.html#a019b5a86a263bdd8d5bc4914a188a66b">dGain</a>,
<a name="l00139"></a>00139         cConfig.<a class="code" href="class_c_mindset_config.html#a8a9e285489025534aff5e2754fdaf1e3">bRProp</a>);
<a name="l00140"></a>00140 
<a name="l00141"></a>00141     <a class="code" href="class_neural_net.html#ade1f7df3aff13a38ef212ce990774c57" title="Is the net trained.">iTrained</a> = cConfig.<a class="code" href="class_c_mindset_config.html#a1993170136d6fae93daa0212d8258310">iTrainingStatus</a>;
<a name="l00142"></a>00142 
<a name="l00143"></a>00143     <span class="comment">// Load the means and std deviation arrays</span>
<a name="l00144"></a>00144     <a class="code" href="class_neural_net.html#ab731e89f294639ee1de018a02204d47e">vInputMean</a> = cConfig.<a class="code" href="class_c_mindset_config.html#adbd662679b5fd5a2f0a9ca17f2be33ed">vInputMean</a>;
<a name="l00145"></a>00145     <a class="code" href="class_neural_net.html#abcbc27b95edbba0f3a0b0be9caeea104" title="Save the standard deviation for all outputs.">vInputStdDev</a> = cConfig.<a class="code" href="class_c_mindset_config.html#a1cf0ec30c7d3eb07490c0e13fbc80595">vInputStdDev</a>;
<a name="l00146"></a>00146     <a class="code" href="class_neural_net.html#a87b0d2e664dda7def01e437cd1c69028" title="Save the mean for all outputs.">vOutputMean</a> = cConfig.<a class="code" href="class_c_mindset_config.html#ade0d21bef61cfb7e9e5deb47740a287c">vOutputMean</a>;
<a name="l00147"></a>00147     <a class="code" href="class_neural_net.html#af80ee309cb980881a48a2b06ec8ec94c" title="Save the standard deviation for all outputs.">vOutputStdDev</a> = cConfig.<a class="code" href="class_c_mindset_config.html#aacf268b12983ead34570a212b7d395b6">vOutputStdDev</a>;
<a name="l00148"></a>00148 
<a name="l00149"></a>00149     <span class="comment">// Set all the weights</span>
<a name="l00150"></a>00150     <span class="comment">// Save all weights</span>
<a name="l00151"></a>00151     <span class="keywordflow">for</span>(layer = 0; layer &lt; <a class="code" href="class_neural_net.html#a0e202814817d8acf923bbb8481a79e11" title="Number of layers.">layers</a>; layer++)
<a name="l00152"></a>00152     {
<a name="l00153"></a>00153         <span class="keywordflow">for</span>(pe = 0; pe &lt; <a class="code" href="class_neural_net.html#abeb6e703d60a6dbe3a979aa168d8ea1a" title="For external use.">pelements</a>[layer]; pe++)
<a name="l00154"></a>00154         {
<a name="l00155"></a>00155             <span class="keywordflow">for</span>(input = 0; input &lt; <a class="code" href="class_neural_net.html#af2ba1bf36dda0676496d3f8a5c5cac52" title="Neuron layers.">PElement</a>[layer][pe]-&gt;<a class="code" href="class_neuron.html#a04d04b23fae8548335721a06f5a1a6f0" title="Number of inputs.">inputs</a>; input++)
<a name="l00156"></a>00156             {
<a name="l00157"></a>00157                 <a class="code" href="class_neural_net.html#a0a89a2bb8dd8e5f697a1723bd91cbfd7" title="Set stored weights.">SetWeight</a>(layer, pe, input, cConfig.<a class="code" href="class_c_mindset_config.html#a13663407540217b91722b5a6c2854ef1">vWeights</a>[iWeightCount++]);
<a name="l00158"></a>00158             };
<a name="l00159"></a>00159         };
<a name="l00160"></a>00160     };
<a name="l00161"></a>00161 
<a name="l00162"></a>00162     <span class="comment">// Set the neuron labels</span>
<a name="l00163"></a>00163     <span class="comment">// Inputs</span>
<a name="l00164"></a>00164     layer = 0;
<a name="l00165"></a>00165     <span class="keywordflow">for</span>(pe = 0; pe &lt; <a class="code" href="class_neural_net.html#abeb6e703d60a6dbe3a979aa168d8ea1a" title="For external use.">pelements</a>[layer]; pe++)
<a name="l00166"></a>00166     {
<a name="l00167"></a>00167         <span class="keywordflow">if</span> (iLabel &lt; (<span class="keywordtype">int</span>) cConfig.<a class="code" href="class_c_mindset_config.html#a6602b32d0e4dbfed84fe6d5e65bd29c6">vLabels</a>.size())
<a name="l00168"></a>00168         {
<a name="l00169"></a>00169             <a class="code" href="class_neural_net.html#af2ba1bf36dda0676496d3f8a5c5cac52" title="Neuron layers.">PElement</a>[layer][pe]-&gt;<a class="code" href="class_neuron.html#a6724c015e67ed24f2a51437dde1167be" title="Allocate the label string and set it.">SetNeuronLabel</a>(cConfig.<a class="code" href="class_c_mindset_config.html#a6602b32d0e4dbfed84fe6d5e65bd29c6">vLabels</a>[iLabel++].c_str());
<a name="l00170"></a>00170         };
<a name="l00171"></a>00171     };
<a name="l00172"></a>00172     <span class="comment">// Outputs</span>
<a name="l00173"></a>00173     layer = layers - 1;
<a name="l00174"></a>00174     <span class="keywordflow">for</span>(pe = 0; pe &lt; pelements[layer]; pe++)
<a name="l00175"></a>00175     {
<a name="l00176"></a>00176         <span class="keywordflow">if</span> (iLabel &lt; (<span class="keywordtype">int</span>) cConfig.<a class="code" href="class_c_mindset_config.html#a6602b32d0e4dbfed84fe6d5e65bd29c6">vLabels</a>.size())
<a name="l00177"></a>00177         {
<a name="l00178"></a>00178             <a class="code" href="class_neural_net.html#af2ba1bf36dda0676496d3f8a5c5cac52" title="Neuron layers.">PElement</a>[layer][pe]-&gt;<a class="code" href="class_neuron.html#a6724c015e67ed24f2a51437dde1167be" title="Allocate the label string and set it.">SetNeuronLabel</a>(cConfig.<a class="code" href="class_c_mindset_config.html#a6602b32d0e4dbfed84fe6d5e65bd29c6">vLabels</a>[iLabel++].c_str());
<a name="l00179"></a>00179         };
<a name="l00180"></a>00180     };
<a name="l00181"></a>00181 
<a name="l00182"></a>00182     <span class="comment">// All the weights have to be set.</span>
<a name="l00183"></a>00183     <span class="keywordflow">return</span>(0);
<a name="l00184"></a>00184 };
<a name="l00186"></a>00186 
<a name="l00187"></a>00187 
<a name="l00188"></a>00188 
<a name="l00190"></a>00190 <span class="comment">//  Save a NeuralNet to file.  This will include saved weights.</span>
<a name="l00191"></a>00191 <span class="comment">//</span>
<a name="l00192"></a>00192 
<a name="l00193"></a><a class="code" href="class_neural_net.html#a0d0abc6ad705c079409455a04d37526d">00193</a> <span class="keywordtype">int</span> <a class="code" href="class_neural_net.html#a0d0abc6ad705c079409455a04d37526d" title="Save network.">NeuralNet::SaveNetwork</a>(<span class="keyword">const</span> <span class="keywordtype">char</span> * szNetworkFile)
<a name="l00194"></a>00194 { <span class="comment">// Put this in the same class as the code that reads and parses the file</span>
<a name="l00195"></a>00195     FILE *pFile = NULL;
<a name="l00196"></a>00196     <span class="keywordtype">char</span> szBuffer[1024];
<a name="l00197"></a>00197     <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> layer;
<a name="l00198"></a>00198     <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> pe;
<a name="l00199"></a>00199     <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> input;
<a name="l00200"></a>00200     <span class="keywordtype">unsigned</span> <span class="keywordtype">long</span> lCRC = 0xFFFFFFFF;
<a name="l00201"></a>00201 
<a name="l00202"></a>00202     <span class="comment">// Open the file.  This will overwrite a file that already exists</span>
<a name="l00203"></a>00203     pFile = ::fopen(szNetworkFile, (<span class="stringliteral">&quot;wb&quot;</span>));
<a name="l00204"></a>00204     <span class="keywordflow">if</span> (!pFile)
<a name="l00205"></a>00205         <span class="keywordflow">return</span>(errno);
<a name="l00206"></a>00206 
<a name="l00207"></a>00207     <span class="comment">// Start saving stuff</span>
<a name="l00208"></a>00208     <span class="comment">// MindSetNetwork tag</span>
<a name="l00209"></a>00209     <a class="code" href="class_neural_net.html#acd5188d94ac78e7a36b283af970b1ce4" title="Write a line in the file and update the CRC.">FileWriteLine</a>(pFile, <a class="code" href="_text_8cpp.html#ab065e254a0e23ae6a7536f1211b515b8">szMindSetNetwork</a>, lCRC);
<a name="l00210"></a>00210     <span class="comment">// Configuration </span>
<a name="l00211"></a>00211     ::sprintf(szBuffer, <a class="code" href="_text_8cpp.html#ab38d17f86a1045609079c3ef44d042a2">szConfiguration</a>, <a class="code" href="class_neural_net.html#a0e202814817d8acf923bbb8481a79e11" title="Number of layers.">layers</a>);
<a name="l00212"></a>00212     <a class="code" href="class_neural_net.html#acd5188d94ac78e7a36b283af970b1ce4" title="Write a line in the file and update the CRC.">FileWriteLine</a>(pFile, szBuffer, lCRC);
<a name="l00213"></a>00213     <span class="comment">// Layers</span>
<a name="l00214"></a>00214     <span class="keywordflow">for</span>(layer = 0; layer &lt; (int) <a class="code" href="class_neural_net.html#a0e202814817d8acf923bbb8481a79e11" title="Number of layers.">layers</a>; layer++)
<a name="l00215"></a>00215     {
<a name="l00216"></a>00216         <span class="keywordtype">int</span> iType = <a class="code" href="class_neural_net.html#a8243ba142eead5765e0959f57d1747f3a2e11150086e6ef07cc27868536c2edd0">HIDDEN</a>;
<a name="l00217"></a>00217         <span class="keywordflow">if</span> (!layer)
<a name="l00218"></a>00218             iType = <a class="code" href="class_neural_net.html#a8243ba142eead5765e0959f57d1747f3a877f4f35bb41b96f3839ea421c35c353" title="Identify the layer a neuron belongs to.">INPUT</a>;
<a name="l00219"></a>00219         <span class="keywordflow">else</span>
<a name="l00220"></a>00220             <span class="keywordflow">if</span> (layer == (<a class="code" href="class_neural_net.html#a0e202814817d8acf923bbb8481a79e11" title="Number of layers.">layers</a> - 1))
<a name="l00221"></a>00221             iType = <a class="code" href="class_neural_net.html#a8243ba142eead5765e0959f57d1747f3aa2b0cbc10f8b696b6f419109e7fac591">OUTPUT</a>;
<a name="l00222"></a>00222         ::sprintf(szBuffer, <a class="code" href="_text_8cpp.html#a49f8d5b38c7d41fb904fccbb49e0155b">szLayer</a>, iType, <a class="code" href="class_neural_net.html#abeb6e703d60a6dbe3a979aa168d8ea1a" title="For external use.">pelements</a>[layer]);
<a name="l00223"></a>00223         <a class="code" href="class_neural_net.html#acd5188d94ac78e7a36b283af970b1ce4" title="Write a line in the file and update the CRC.">FileWriteLine</a>(pFile, szBuffer, lCRC);
<a name="l00224"></a>00224     };
<a name="l00225"></a>00225     <span class="comment">// Neuron labels</span>
<a name="l00226"></a>00226     <span class="comment">// Inputs</span>
<a name="l00227"></a>00227     layer = 0;
<a name="l00228"></a>00228     <span class="keywordflow">for</span>(pe = 0; pe &lt; <a class="code" href="class_neural_net.html#abeb6e703d60a6dbe3a979aa168d8ea1a" title="For external use.">pelements</a>[layer]; pe++)
<a name="l00229"></a>00229     {
<a name="l00230"></a>00230         ::sprintf(szBuffer, <a class="code" href="_text_8cpp.html#abf392bae51567715e0e41efd38768837">szLabel</a>, <a class="code" href="class_neural_net.html#af2ba1bf36dda0676496d3f8a5c5cac52" title="Neuron layers.">PElement</a>[layer][pe]-&gt;cLabel.c_str());
<a name="l00231"></a>00231         <a class="code" href="class_neural_net.html#acd5188d94ac78e7a36b283af970b1ce4" title="Write a line in the file and update the CRC.">FileWriteLine</a>(pFile, szBuffer, lCRC);
<a name="l00232"></a>00232     };
<a name="l00233"></a>00233     <span class="comment">// Outputs</span>
<a name="l00234"></a>00234     layer = <a class="code" href="class_neural_net.html#a0e202814817d8acf923bbb8481a79e11" title="Number of layers.">layers</a> - 1;
<a name="l00235"></a>00235     <span class="keywordflow">for</span>(pe = 0; pe &lt; pelements[layer]; pe++)
<a name="l00236"></a>00236     {
<a name="l00237"></a>00237         ::sprintf(szBuffer, <a class="code" href="_text_8cpp.html#abf392bae51567715e0e41efd38768837">szLabel</a>, <a class="code" href="class_neural_net.html#af2ba1bf36dda0676496d3f8a5c5cac52" title="Neuron layers.">PElement</a>[layer][pe]-&gt;cLabel.c_str());
<a name="l00238"></a>00238         <a class="code" href="class_neural_net.html#acd5188d94ac78e7a36b283af970b1ce4" title="Write a line in the file and update the CRC.">FileWriteLine</a>(pFile, szBuffer, lCRC);
<a name="l00239"></a>00239     };
<a name="l00240"></a>00240 
<a name="l00241"></a>00241     <span class="comment">// Allowable error</span>
<a name="l00242"></a>00242     ::sprintf(szBuffer, <a class="code" href="_text_8cpp.html#ae75b96a24f43154188f2100294ce0126">szAllowableError</a>, <a class="code" href="class_neural_net.html#a32c7a3ced047c1d71e99f2c4b51dc14e" title="Allowable error.">error</a>);
<a name="l00243"></a>00243     <a class="code" href="class_neural_net.html#acd5188d94ac78e7a36b283af970b1ce4" title="Write a line in the file and update the CRC.">FileWriteLine</a>(pFile, szBuffer, lCRC);
<a name="l00244"></a>00244     <span class="comment">// Learn rate</span>
<a name="l00245"></a>00245     ::sprintf(szBuffer, <a class="code" href="_text_8cpp.html#a174324a32eb526846014487a4b1a8ac9">szLearnRate</a>, <a class="code" href="class_neural_net.html#a47b081356cece6d51cda1d9a546cf53c" title="Learn rate.">delta</a>);
<a name="l00246"></a>00246     <a class="code" href="class_neural_net.html#acd5188d94ac78e7a36b283af970b1ce4" title="Write a line in the file and update the CRC.">FileWriteLine</a>(pFile, szBuffer, lCRC);
<a name="l00247"></a>00247     <span class="comment">// Momentum</span>
<a name="l00248"></a>00248     ::sprintf(szBuffer, <a class="code" href="_text_8cpp.html#ae2b0c692b8ffca94564e543d6be52084">szMomentum</a>, <a class="code" href="class_neural_net.html#ae2abb290d0c972e07df4a6b8ba37a910" title="Momentum factor.">momentum</a>);
<a name="l00249"></a>00249     <a class="code" href="class_neural_net.html#acd5188d94ac78e7a36b283af970b1ce4" title="Write a line in the file and update the CRC.">FileWriteLine</a>(pFile, szBuffer, lCRC);
<a name="l00250"></a>00250     <span class="comment">// Momentum</span>
<a name="l00251"></a>00251     ::sprintf(szBuffer, <a class="code" href="_text_8cpp.html#a002337b56993a5d1f2ab75864a5f44ad">szGain</a>, <a class="code" href="class_neural_net.html#a1d819b4e7babcd2149f3382afc675090" title="The gain.">dGain</a>);
<a name="l00252"></a>00252     <a class="code" href="class_neural_net.html#acd5188d94ac78e7a36b283af970b1ce4" title="Write a line in the file and update the CRC.">FileWriteLine</a>(pFile, szBuffer, lCRC);
<a name="l00253"></a>00253     <span class="comment">// Use RProp</span>
<a name="l00254"></a>00254     ::sprintf(szBuffer, <a class="code" href="_text_8cpp.html#a1503d096db55c661f0aba91a0cdbc560">szRProp</a>, <a class="code" href="class_neural_net.html#a6e200122a6165c503741b9d54b735e22" title="Use the RProp algorithm for training.">bUseRProp</a>);
<a name="l00255"></a>00255     <a class="code" href="class_neural_net.html#acd5188d94ac78e7a36b283af970b1ce4" title="Write a line in the file and update the CRC.">FileWriteLine</a>(pFile, szBuffer, lCRC);
<a name="l00256"></a>00256     <span class="comment">// Training status</span>
<a name="l00257"></a>00257     ::sprintf(szBuffer, <a class="code" href="_text_8cpp.html#ae849fbf8227f11ef24e5b38aa06e07e2">szTrainingStatus</a>, <a class="code" href="class_neural_net.html#ade1f7df3aff13a38ef212ce990774c57" title="Is the net trained.">iTrained</a>);
<a name="l00258"></a>00258     <a class="code" href="class_neural_net.html#acd5188d94ac78e7a36b283af970b1ce4" title="Write a line in the file and update the CRC.">FileWriteLine</a>(pFile, szBuffer, lCRC);
<a name="l00259"></a>00259     <span class="comment">// End configuration</span>
<a name="l00260"></a>00260     <a class="code" href="class_neural_net.html#acd5188d94ac78e7a36b283af970b1ce4" title="Write a line in the file and update the CRC.">FileWriteLine</a>(pFile, <a class="code" href="_text_8cpp.html#ae123bf2381f7166aaf6356c0698ff086">szEndConfiguration</a>, lCRC);
<a name="l00261"></a>00261     <span class="comment">// Saved training data</span>
<a name="l00262"></a>00262     <a class="code" href="class_neural_net.html#acd5188d94ac78e7a36b283af970b1ce4" title="Write a line in the file and update the CRC.">FileWriteLine</a>(pFile, <a class="code" href="_text_8cpp.html#adce5f536f599a7967e26597b1296b635">szSavedTrainingData</a>, lCRC);
<a name="l00263"></a>00263     <span class="comment">// Scaling</span>
<a name="l00264"></a>00264     <a class="code" href="class_neural_net.html#acd5188d94ac78e7a36b283af970b1ce4" title="Write a line in the file and update the CRC.">FileWriteLine</a>(pFile, <a class="code" href="_text_8cpp.html#a04212abcac52cc75f7e2ac007d33765a">szScaling</a>, lCRC);
<a name="l00265"></a>00265     <span class="comment">// Inputs</span>
<a name="l00266"></a>00266     <a class="code" href="class_neural_net.html#acd5188d94ac78e7a36b283af970b1ce4" title="Write a line in the file and update the CRC.">FileWriteLine</a>(pFile, <a class="code" href="_text_8cpp.html#a34390e91e1d7ce828c1ddb2401cb5a93">szInput</a>, lCRC);
<a name="l00267"></a>00267     <span class="comment">// Scaling stuff</span>
<a name="l00268"></a>00268     <span class="keywordflow">for</span>(<span class="keywordtype">int</span> iX = 0; iX &lt; (int) <a class="code" href="class_neural_net.html#ab731e89f294639ee1de018a02204d47e">vInputMean</a>.size(); iX++)
<a name="l00269"></a>00269     { <span class="comment">// Mean</span>
<a name="l00270"></a>00270         ::sprintf(szBuffer, <a class="code" href="_text_8cpp.html#a9e1bf97808870226abb3b0081a039102">szMean</a>, <a class="code" href="class_neural_net.html#ab731e89f294639ee1de018a02204d47e">vInputMean</a>[iX]);
<a name="l00271"></a>00271         <a class="code" href="class_neural_net.html#acd5188d94ac78e7a36b283af970b1ce4" title="Write a line in the file and update the CRC.">FileWriteLine</a>(pFile, szBuffer, lCRC);
<a name="l00272"></a>00272         <span class="comment">// Std dev</span>
<a name="l00273"></a>00273         ::sprintf(szBuffer, <a class="code" href="_text_8cpp.html#a213e0b60838ab2b52bd86eabf7d893a1">szStdDev</a>, <a class="code" href="class_neural_net.html#abcbc27b95edbba0f3a0b0be9caeea104" title="Save the standard deviation for all outputs.">vInputStdDev</a>[iX]);
<a name="l00274"></a>00274         <a class="code" href="class_neural_net.html#acd5188d94ac78e7a36b283af970b1ce4" title="Write a line in the file and update the CRC.">FileWriteLine</a>(pFile, szBuffer, lCRC);
<a name="l00275"></a>00275     };
<a name="l00276"></a>00276     <span class="comment">// End inputs</span>
<a name="l00277"></a>00277     <a class="code" href="class_neural_net.html#acd5188d94ac78e7a36b283af970b1ce4" title="Write a line in the file and update the CRC.">FileWriteLine</a>(pFile, <a class="code" href="_text_8cpp.html#adc047cfd59cb32a3882e8f5452faa2d7">szEndInput</a>, lCRC);
<a name="l00278"></a>00278     <span class="comment">// Outputs</span>
<a name="l00279"></a>00279     <a class="code" href="class_neural_net.html#acd5188d94ac78e7a36b283af970b1ce4" title="Write a line in the file and update the CRC.">FileWriteLine</a>(pFile, <a class="code" href="_text_8cpp.html#a8765c6499b48b87c6db9778b9b76a569">szOutput</a>, lCRC);
<a name="l00280"></a>00280     <span class="comment">// Scaling stuff</span>
<a name="l00281"></a>00281     <span class="keywordflow">for</span>(<span class="keywordtype">int</span> iX = 0; iX &lt; (int) <a class="code" href="class_neural_net.html#a87b0d2e664dda7def01e437cd1c69028" title="Save the mean for all outputs.">vOutputMean</a>.size(); iX++)
<a name="l00282"></a>00282     { <span class="comment">// Mean</span>
<a name="l00283"></a>00283         ::sprintf(szBuffer, <a class="code" href="_text_8cpp.html#a9e1bf97808870226abb3b0081a039102">szMean</a>, <a class="code" href="class_neural_net.html#a87b0d2e664dda7def01e437cd1c69028" title="Save the mean for all outputs.">vOutputMean</a>[iX]);
<a name="l00284"></a>00284         <a class="code" href="class_neural_net.html#acd5188d94ac78e7a36b283af970b1ce4" title="Write a line in the file and update the CRC.">FileWriteLine</a>(pFile, szBuffer, lCRC);
<a name="l00285"></a>00285         <span class="comment">// Std dev</span>
<a name="l00286"></a>00286         ::sprintf(szBuffer, <a class="code" href="_text_8cpp.html#a213e0b60838ab2b52bd86eabf7d893a1">szStdDev</a>, <a class="code" href="class_neural_net.html#af80ee309cb980881a48a2b06ec8ec94c" title="Save the standard deviation for all outputs.">vOutputStdDev</a>[iX]);
<a name="l00287"></a>00287         <a class="code" href="class_neural_net.html#acd5188d94ac78e7a36b283af970b1ce4" title="Write a line in the file and update the CRC.">FileWriteLine</a>(pFile, szBuffer, lCRC);
<a name="l00288"></a>00288     };
<a name="l00289"></a>00289     <span class="comment">// End outputs</span>
<a name="l00290"></a>00290     <a class="code" href="class_neural_net.html#acd5188d94ac78e7a36b283af970b1ce4" title="Write a line in the file and update the CRC.">FileWriteLine</a>(pFile, <a class="code" href="_text_8cpp.html#a8afef230fc1068c1cde552e1f681ae19">szEndOutput</a>, lCRC);
<a name="l00291"></a>00291     <span class="comment">// End scaling</span>
<a name="l00292"></a>00292     <a class="code" href="class_neural_net.html#acd5188d94ac78e7a36b283af970b1ce4" title="Write a line in the file and update the CRC.">FileWriteLine</a>(pFile, <a class="code" href="_text_8cpp.html#a30f95fff62a80d7d5e16edb67a1e9f1c">szEndScaling</a>, lCRC);
<a name="l00293"></a>00293     <span class="comment">// Weights</span>
<a name="l00294"></a>00294     <a class="code" href="class_neural_net.html#acd5188d94ac78e7a36b283af970b1ce4" title="Write a line in the file and update the CRC.">FileWriteLine</a>(pFile, <a class="code" href="_text_8cpp.html#a9bff3e26a271dc54994ec68988130aa6">szWeights</a>, lCRC);
<a name="l00295"></a>00295     <span class="comment">// Save all weights</span>
<a name="l00296"></a>00296     <span class="keywordflow">for</span>(layer = 0; layer &lt; <a class="code" href="class_neural_net.html#a0e202814817d8acf923bbb8481a79e11" title="Number of layers.">layers</a>; layer++)
<a name="l00297"></a>00297     {
<a name="l00298"></a>00298         <span class="keywordflow">for</span>(pe = 0; pe &lt; pelements[layer]; pe++)
<a name="l00299"></a>00299         {
<a name="l00300"></a>00300             <span class="keywordflow">for</span>(input = 0; input &lt; <a class="code" href="class_neural_net.html#af2ba1bf36dda0676496d3f8a5c5cac52" title="Neuron layers.">PElement</a>[layer][pe]-&gt;<a class="code" href="class_neuron.html#a04d04b23fae8548335721a06f5a1a6f0" title="Number of inputs.">inputs</a>; input++)
<a name="l00301"></a>00301             {
<a name="l00302"></a>00302                 <span class="keywordtype">double</span> dWeight = <a class="code" href="class_neural_net.html#ad096ce60aa788e444af2c3c92ccec33f" title="Get calculated weights, used after learning.">GetWeight</a>(layer, pe, input);
<a name="l00303"></a>00303                 ::sprintf(szBuffer, <span class="stringliteral">&quot;%f&quot;</span>, dWeight);
<a name="l00304"></a>00304                 <a class="code" href="class_neural_net.html#acd5188d94ac78e7a36b283af970b1ce4" title="Write a line in the file and update the CRC.">FileWriteLine</a>(pFile, szBuffer, lCRC);
<a name="l00305"></a>00305                 <span class="keywordflow">if</span> (layer != layers - 1 || pe != <a class="code" href="class_neural_net.html#ae3f57ff94e97b1b04f49787b58cf2f80" title="For internal use, this count includes bias units.">elements</a>[layer] - 1 || input != <a class="code" href="class_neural_net.html#af2ba1bf36dda0676496d3f8a5c5cac52" title="Neuron layers.">PElement</a>[layer][pe]-&gt;inputs - 1)
<a name="l00306"></a>00306                 {
<a name="l00307"></a>00307                     <a class="code" href="class_neural_net.html#acd5188d94ac78e7a36b283af970b1ce4" title="Write a line in the file and update the CRC.">FileWriteLine</a>(pFile, <a class="code" href="_text_8cpp.html#a9582e474b02ca559f7459bc1a521b065">szComma</a>, lCRC);
<a name="l00308"></a>00308                 };
<a name="l00309"></a>00309             };
<a name="l00310"></a>00310         };
<a name="l00311"></a>00311     };
<a name="l00312"></a>00312     <span class="comment">// End weights</span>
<a name="l00313"></a>00313     <a class="code" href="class_neural_net.html#acd5188d94ac78e7a36b283af970b1ce4" title="Write a line in the file and update the CRC.">FileWriteLine</a>(pFile, <a class="code" href="_text_8cpp.html#aef89a677ac4549a77d961640285dbd49">szEndWeights</a>, lCRC);
<a name="l00314"></a>00314     <span class="comment">// End saved training data</span>
<a name="l00315"></a>00315     <a class="code" href="class_neural_net.html#acd5188d94ac78e7a36b283af970b1ce4" title="Write a line in the file and update the CRC.">FileWriteLine</a>(pFile, <a class="code" href="_text_8cpp.html#ae20ce966c6d670ddf42eac80d6a71476">szEndSavedTrainingData</a>, lCRC);
<a name="l00316"></a>00316     <span class="comment">// Verification code</span>
<a name="l00317"></a>00317     ::sprintf(szBuffer, <a class="code" href="_text_8cpp.html#a6b51affa1d7126cf7148adac88e76aa9">szCRC</a>, lCRC);
<a name="l00318"></a>00318     <a class="code" href="class_neural_net.html#acd5188d94ac78e7a36b283af970b1ce4" title="Write a line in the file and update the CRC.">FileWriteLine</a>(pFile, szBuffer, lCRC);
<a name="l00319"></a>00319     <span class="comment">// MindSetNetwork</span>
<a name="l00320"></a>00320     <a class="code" href="class_neural_net.html#acd5188d94ac78e7a36b283af970b1ce4" title="Write a line in the file and update the CRC.">FileWriteLine</a>(pFile, <a class="code" href="_text_8cpp.html#ab3f18fd1e62e98d8ea876e23d20567a6">szEndMindSetNetwork</a>, lCRC);
<a name="l00321"></a>00321 
<a name="l00322"></a>00322     <span class="comment">// Close the file</span>
<a name="l00323"></a>00323     ::fclose(pFile);
<a name="l00324"></a>00324 
<a name="l00325"></a>00325     <span class="keywordflow">return</span>(0);
<a name="l00326"></a>00326 };
<a name="l00328"></a>00328 
<a name="l00329"></a>00329 
<a name="l00330"></a>00330 
<a name="l00331"></a>00331 
<a name="l00333"></a>00333 <span class="comment">//</span>
<a name="l00334"></a>00334 <span class="comment">//  Write a line in the config file and update the CRC</span>
<a name="l00335"></a>00335 <span class="comment">//</span>
<a name="l00336"></a>00336 
<a name="l00337"></a><a class="code" href="class_neural_net.html#acd5188d94ac78e7a36b283af970b1ce4">00337</a> <span class="keywordtype">int</span> <a class="code" href="class_neural_net.html#acd5188d94ac78e7a36b283af970b1ce4" title="Write a line in the file and update the CRC.">NeuralNet::FileWriteLine</a>(FILE *pFile, <span class="keywordtype">char</span> *pBuffer, <span class="keywordtype">unsigned</span> <span class="keywordtype">long</span> &amp;lCRC)
<a name="l00338"></a>00338 {
<a name="l00339"></a>00339     CRC32 cCRC;
<a name="l00340"></a>00340     <span class="keywordtype">int</span> iReturn;
<a name="l00341"></a>00341 
<a name="l00342"></a>00342     <span class="comment">// End weights</span>
<a name="l00343"></a>00343     iReturn = ::fwrite(pBuffer, 1, ::strlen(pBuffer), pFile);
<a name="l00344"></a>00344     lCRC = cCRC.CalcCRC(lCRC, (<span class="keywordtype">unsigned</span> <span class="keywordtype">char</span> *) pBuffer, ::strlen(pBuffer));
<a name="l00345"></a>00345 
<a name="l00346"></a>00346     <span class="keywordflow">return</span>(iReturn);
<a name="l00347"></a>00347 };
<a name="l00349"></a>00349 
<a name="l00350"></a>00350 
<a name="l00351"></a>00351 
<a name="l00353"></a>00353 <span class="comment">//</span>
<a name="l00354"></a>00354 <span class="comment">// This allows a derived class to have NeuralNet allocate a derived Neuron</span>
<a name="l00355"></a>00355 <span class="comment">//</span>
<a name="l00356"></a>00356 <span class="comment">// AParent - pointer to parent NeuralNet</span>
<a name="l00357"></a>00357 <span class="comment">// num_inputs - number of inputs to this neuron (# neurons in the previous layer)</span>
<a name="l00358"></a>00358 <span class="comment">// anid - a unique id for this neuron</span>
<a name="l00359"></a>00359 <span class="comment">// uLayer - one of the enums, INPUT, HIDDEN, OUTPUT</span>
<a name="l00360"></a>00360 <span class="comment">//</span>
<a name="l00361"></a>00361 
<a name="l00362"></a><a class="code" href="class_neural_net.html#a6b997859c3d6c4918a19901f6be27e84">00362</a> <a class="code" href="class_neuron.html">Neuron</a> *<a class="code" href="class_neural_net.html#a6b997859c3d6c4918a19901f6be27e84" title="This allows a derived class to have NeuralNet allocate a derived Neuron.">NeuralNet::AllocateNeuron</a>(<a class="code" href="class_neural_net.html">NeuralNet</a> *AParent, <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> num_inputs, <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> element, <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> uLayer)
<a name="l00363"></a>00363 {
<a name="l00364"></a>00364     <span class="keywordflow">return</span>(<span class="keyword">new</span> <a class="code" href="class_neural_net.html#aa410d74ba34b18a9f6bdf24323c4ee5b">Neuron</a>(AParent, num_inputs, element));
<a name="l00365"></a>00365 };
<a name="l00367"></a>00367 
<a name="l00368"></a>00368 
<a name="l00369"></a>00369 
<a name="l00370"></a>00370 
<a name="l00372"></a>00372 <span class="comment">//</span>
<a name="l00373"></a>00373 <span class="comment">// Created successfully?</span>
<a name="l00374"></a>00374 <span class="comment">//</span>
<a name="l00375"></a>00375 
<a name="l00376"></a><a class="code" href="class_neural_net.html#a7b5158edc2da11cd17a4cb3b63897399">00376</a> <span class="keywordtype">bool</span> <a class="code" href="class_neural_net.html#a7b5158edc2da11cd17a4cb3b63897399">NeuralNet::Created</a>()
<a name="l00377"></a>00377 {
<a name="l00378"></a>00378     <span class="keywordflow">return</span>(<a class="code" href="class_neural_net.html#a864417aa22e18e9bb4fc14b1664b65ff" title="Creation flag.">bCreated</a>);
<a name="l00379"></a>00379 };
<a name="l00381"></a>00381 
<a name="l00382"></a>00382 
<a name="l00383"></a>00383 
<a name="l00385"></a>00385 <span class="comment">//    Destructor for NeuralNet</span>
<a name="l00386"></a>00386 <span class="comment">//</span>
<a name="l00387"></a>00387 
<a name="l00388"></a><a class="code" href="class_neural_net.html#afd68e306bdf39aaa8c6ef016e4da18a1">00388</a> <a class="code" href="class_neural_net.html#afd68e306bdf39aaa8c6ef016e4da18a1" title="Destructor.">NeuralNet::~NeuralNet</a>()
<a name="l00389"></a>00389 {
<a name="l00390"></a>00390     <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> layer;
<a name="l00391"></a>00391     <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> pe;
<a name="l00392"></a>00392 
<a name="l00393"></a>00393     <span class="comment">// Delete allocated neurons</span>
<a name="l00394"></a>00394     <span class="keywordflow">if</span> (<a class="code" href="class_neural_net.html#af2ba1bf36dda0676496d3f8a5c5cac52" title="Neuron layers.">PElement</a>)
<a name="l00395"></a>00395     {
<a name="l00396"></a>00396         <span class="keywordflow">for</span>(layer = 0; layer &lt; <a class="code" href="class_neural_net.html#a0e202814817d8acf923bbb8481a79e11" title="Number of layers.">layers</a>; layer++)
<a name="l00397"></a>00397         {
<a name="l00398"></a>00398             <span class="keywordflow">if</span> (<a class="code" href="class_neural_net.html#af2ba1bf36dda0676496d3f8a5c5cac52" title="Neuron layers.">PElement</a>[layer])
<a name="l00399"></a>00399             {
<a name="l00400"></a>00400                 <span class="keywordflow">for</span>(pe = 0; pe &lt; <a class="code" href="class_neural_net.html#ae3f57ff94e97b1b04f49787b58cf2f80" title="For internal use, this count includes bias units.">elements</a>[layer]; pe++)
<a name="l00401"></a>00401                 {
<a name="l00402"></a>00402                     <span class="keywordflow">if</span> (<a class="code" href="class_neural_net.html#af2ba1bf36dda0676496d3f8a5c5cac52" title="Neuron layers.">PElement</a>[layer][pe])
<a name="l00403"></a>00403                         <span class="keyword">delete</span> <a class="code" href="class_neural_net.html#af2ba1bf36dda0676496d3f8a5c5cac52" title="Neuron layers.">PElement</a>[layer][pe];
<a name="l00404"></a>00404                 };
<a name="l00405"></a>00405                 <span class="keyword">delete</span>[] <a class="code" href="class_neural_net.html#af2ba1bf36dda0676496d3f8a5c5cac52" title="Neuron layers.">PElement</a>[layer];
<a name="l00406"></a>00406             }
<a name="l00407"></a>00407         };
<a name="l00408"></a>00408         <span class="keyword">delete</span>[] <a class="code" href="class_neural_net.html#af2ba1bf36dda0676496d3f8a5c5cac52" title="Neuron layers.">PElement</a>;
<a name="l00409"></a>00409     };
<a name="l00410"></a>00410     <span class="keywordflow">if</span> (<a class="code" href="class_neural_net.html#ae3f57ff94e97b1b04f49787b58cf2f80" title="For internal use, this count includes bias units.">elements</a>)
<a name="l00411"></a>00411         <span class="keyword">delete</span>[] <a class="code" href="class_neural_net.html#ae3f57ff94e97b1b04f49787b58cf2f80" title="For internal use, this count includes bias units.">elements</a>;
<a name="l00412"></a>00412     <span class="keywordflow">if</span> (<a class="code" href="class_neural_net.html#abeb6e703d60a6dbe3a979aa168d8ea1a" title="For external use.">pelements</a>)
<a name="l00413"></a>00413         <span class="keyword">delete</span>[] <a class="code" href="class_neural_net.html#abeb6e703d60a6dbe3a979aa168d8ea1a" title="For external use.">pelements</a>;
<a name="l00414"></a>00414 
<a name="l00415"></a>00415 }; <span class="comment">// End destructor</span>
<a name="l00417"></a>00417 <span class="comment"></span>
<a name="l00418"></a>00418 
<a name="l00419"></a>00419 
<a name="l00421"></a>00421 <span class="comment">//    Set stored weight</span>
<a name="l00422"></a>00422 <span class="comment">//</span>
<a name="l00423"></a>00423 
<a name="l00424"></a><a class="code" href="class_neural_net.html#a0a89a2bb8dd8e5f697a1723bd91cbfd7">00424</a> <span class="keywordtype">int</span> <a class="code" href="class_neural_net.html#a0a89a2bb8dd8e5f697a1723bd91cbfd7" title="Set stored weights.">NeuralNet::SetWeight</a>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> layer, <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> pe, <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> input, <span class="keywordtype">double</span> weight)
<a name="l00425"></a>00425 {
<a name="l00426"></a>00426     <span class="keywordflow">if</span> (layer &gt;= <a class="code" href="class_neural_net.html#a0e202814817d8acf923bbb8481a79e11" title="Number of layers.">layers</a> || pe &gt;= <a class="code" href="class_neural_net.html#ae3f57ff94e97b1b04f49787b58cf2f80" title="For internal use, this count includes bias units.">elements</a>[layer])
<a name="l00427"></a>00427         <span class="keywordflow">return</span>(-1);
<a name="l00428"></a>00428 
<a name="l00429"></a>00429     <a class="code" href="class_neural_net.html#af2ba1bf36dda0676496d3f8a5c5cac52" title="Neuron layers.">PElement</a>[layer][pe]-&gt;<a class="code" href="class_neuron.html#ad1a0c0ced35f712cc8ace29898154046" title="Weights.">weights</a>[input] = weight;
<a name="l00430"></a>00430 
<a name="l00431"></a>00431     <span class="keywordflow">return</span>(0);
<a name="l00432"></a>00432 };
<a name="l00434"></a>00434 
<a name="l00435"></a>00435 
<a name="l00436"></a>00436 
<a name="l00438"></a>00438 <span class="comment">//    Randomize weights in prepartion for learning</span>
<a name="l00439"></a>00439 <span class="comment">//</span>
<a name="l00440"></a>00440 
<a name="l00441"></a><a class="code" href="class_neural_net.html#a774147214019e55daae829a66af75657">00441</a> <span class="keywordtype">void</span> <a class="code" href="class_neural_net.html#a774147214019e55daae829a66af75657" title="Set all inputs in preparation for learning.">NeuralNet::RandomizeWeights</a>()
<a name="l00442"></a>00442 {
<a name="l00443"></a>00443     <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> layer;
<a name="l00444"></a>00444     <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> pe;
<a name="l00445"></a>00445     <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> input;
<a name="l00446"></a>00446 
<a name="l00447"></a>00447     <span class="keywordflow">for</span>(layer = 0; layer &lt; <a class="code" href="class_neural_net.html#a0e202814817d8acf923bbb8481a79e11" title="Number of layers.">layers</a>; layer++)
<a name="l00448"></a>00448         <span class="keywordflow">for</span>(pe = 0; pe &lt; <a class="code" href="class_neural_net.html#ae3f57ff94e97b1b04f49787b58cf2f80" title="For internal use, this count includes bias units.">elements</a>[layer]; pe++)
<a name="l00449"></a>00449         {
<a name="l00450"></a>00450             <span class="keywordflow">if</span> (!layer) <span class="comment">// Set all weights in input layer to 1</span>
<a name="l00451"></a>00451             {
<a name="l00452"></a>00452                 <span class="keywordflow">for</span>(input = 0; input &lt; <a class="code" href="class_neural_net.html#af2ba1bf36dda0676496d3f8a5c5cac52" title="Neuron layers.">PElement</a>[layer][pe]-&gt;<a class="code" href="class_neuron.html#a04d04b23fae8548335721a06f5a1a6f0" title="Number of inputs.">inputs</a>; input++)
<a name="l00453"></a>00453                     <a class="code" href="class_neural_net.html#af2ba1bf36dda0676496d3f8a5c5cac52" title="Neuron layers.">PElement</a>[layer][pe]-&gt;weights[input] = 1.0f;
<a name="l00454"></a>00454             }
<a name="l00455"></a>00455             <span class="keywordflow">else</span> <span class="comment">// Set each input weight</span>
<a name="l00456"></a>00456                 <a class="code" href="class_neural_net.html#af2ba1bf36dda0676496d3f8a5c5cac52" title="Neuron layers.">PElement</a>[layer][pe]-&gt;<a class="code" href="class_neuron.html#adabb156d10fc8f72c0bd65bd4b67d22a" title="Before any training.">RandomizeNeuronWeights</a>();
<a name="l00457"></a>00457         };
<a name="l00458"></a>00458 };
<a name="l00460"></a>00460 
<a name="l00461"></a>00461 
<a name="l00462"></a>00462 
<a name="l00464"></a>00464 <span class="comment">//    Get an input&#39;s weight</span>
<a name="l00465"></a>00465 <span class="comment">//</span>
<a name="l00466"></a>00466 
<a name="l00467"></a><a class="code" href="class_neural_net.html#ad096ce60aa788e444af2c3c92ccec33f">00467</a> <span class="keywordtype">double</span> <a class="code" href="class_neural_net.html#ad096ce60aa788e444af2c3c92ccec33f" title="Get calculated weights, used after learning.">NeuralNet::GetWeight</a>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> layer, <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> pe, <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> input)
<a name="l00468"></a>00468 {
<a name="l00469"></a>00469     <span class="keywordflow">if</span> (layer &gt;= <a class="code" href="class_neural_net.html#a0e202814817d8acf923bbb8481a79e11" title="Number of layers.">layers</a> || pe &gt;= <a class="code" href="class_neural_net.html#ae3f57ff94e97b1b04f49787b58cf2f80" title="For internal use, this count includes bias units.">elements</a>[layer])
<a name="l00470"></a>00470         <span class="keywordflow">return</span>(-1.0f);
<a name="l00471"></a>00471 
<a name="l00472"></a>00472     <span class="keywordflow">return</span>(<a class="code" href="class_neural_net.html#af2ba1bf36dda0676496d3f8a5c5cac52" title="Neuron layers.">PElement</a>[layer][pe]-&gt;weights[input]);
<a name="l00473"></a>00473 };
<a name="l00475"></a>00475 
<a name="l00476"></a>00476 
<a name="l00477"></a>00477 
<a name="l00479"></a>00479 <span class="comment">//      Set a neuron&#39;s output - used to set value of input neurons</span>
<a name="l00480"></a>00480 <span class="comment">//              </span>
<a name="l00481"></a>00481 <span class="comment">//      Input neurons are linear; i.e. they are used only to store the values to</span>
<a name="l00482"></a>00482 <span class="comment">//      be processed.  So we simply set their outputs directly.  This is rarely</span>
<a name="l00483"></a>00483 <span class="comment">//      used since we really have to scale the inputs in order to process them.</span>
<a name="l00484"></a>00484 <span class="comment">//</span>
<a name="l00485"></a>00485 
<a name="l00486"></a><a class="code" href="class_neural_net.html#ae2b80df9ee9a517e7ef66cd675c45272">00486</a> <span class="keywordtype">int</span> <a class="code" href="class_neural_net.html#ae2b80df9ee9a517e7ef66cd675c45272" title="Set neuron output (for input layer)">NeuralNet::SetNeuronOutput</a>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> layer, <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> pe, <span class="keywordtype">double</span> out)
<a name="l00487"></a>00487 {
<a name="l00488"></a>00488     <span class="keywordflow">if</span> (layer &gt;= <a class="code" href="class_neural_net.html#a0e202814817d8acf923bbb8481a79e11" title="Number of layers.">layers</a> || pe &gt;= <a class="code" href="class_neural_net.html#ae3f57ff94e97b1b04f49787b58cf2f80" title="For internal use, this count includes bias units.">elements</a>[layer])
<a name="l00489"></a>00489         <span class="keywordflow">return</span>(-1);
<a name="l00490"></a>00490 
<a name="l00491"></a>00491     <a class="code" href="class_neural_net.html#af2ba1bf36dda0676496d3f8a5c5cac52" title="Neuron layers.">PElement</a>[layer][pe]-&gt;<a class="code" href="class_neuron.html#ab1583b0659eb2189fe0fd20b4af2ddb3" title="Actual output.">output</a> = out;
<a name="l00492"></a>00492 
<a name="l00493"></a>00493     <span class="keywordflow">return</span>(0);
<a name="l00494"></a>00494 };
<a name="l00496"></a>00496 
<a name="l00497"></a>00497 
<a name="l00499"></a>00499 <span class="comment">//  Set a neuron&#39;s output and scale it in - used to set value of input neurons</span>
<a name="l00500"></a>00500 <span class="comment">//</span>
<a name="l00501"></a>00501 <span class="comment">//      Input neurons are linear; i.e. they are used only to store the values to</span>
<a name="l00502"></a>00502 <span class="comment">//      be processed.  So we simply set their outputs directly.  </span>
<a name="l00503"></a>00503 <span class="comment">//              </span>
<a name="l00504"></a>00504 
<a name="l00505"></a><a class="code" href="class_neural_net.html#a61a8ac4522b7a92a0fd1277f55512ff0">00505</a> <span class="keywordtype">int</span> <a class="code" href="class_neural_net.html#a61a8ac4522b7a92a0fd1277f55512ff0" title="Set neuron output (for input layer) and tell neuron to scale it.">NeuralNet::SetNeuronOutputScaled</a>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> layer, <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> pe, <span class="keywordtype">double</span> out)
<a name="l00506"></a>00506 {
<a name="l00507"></a>00507     <span class="keywordflow">if</span> (layer &gt;= <a class="code" href="class_neural_net.html#a0e202814817d8acf923bbb8481a79e11" title="Number of layers.">layers</a> || pe &gt;= <a class="code" href="class_neural_net.html#ae3f57ff94e97b1b04f49787b58cf2f80" title="For internal use, this count includes bias units.">elements</a>[layer])
<a name="l00508"></a>00508         <span class="keywordflow">return</span>(-1);
<a name="l00509"></a>00509 
<a name="l00510"></a>00510     <a class="code" href="class_neural_net.html#af2ba1bf36dda0676496d3f8a5c5cac52" title="Neuron layers.">PElement</a>[layer][pe]-&gt;<a class="code" href="class_neuron.html#a11bfccb32d07c0a9f048992e36f99f05" title="Scale in a value and set output to it.">ScaleIn</a>(out);
<a name="l00511"></a>00511 
<a name="l00512"></a>00512     <span class="keywordflow">return</span>(0);
<a name="l00513"></a>00513 };
<a name="l00515"></a>00515 
<a name="l00516"></a>00516 
<a name="l00517"></a>00517 
<a name="l00519"></a>00519 <span class="comment">//     Get a neuron&#39;s output</span>
<a name="l00520"></a>00520 <span class="comment">//</span>
<a name="l00521"></a>00521 
<a name="l00522"></a><a class="code" href="class_neural_net.html#a1504d6bcc0f87aa1b9234a527ef0a44d">00522</a> <span class="keywordtype">double</span> <a class="code" href="class_neural_net.html#a1504d6bcc0f87aa1b9234a527ef0a44d" title="Get a particular neuron&#39;s output.">NeuralNet::GetNeuronOutput</a>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> layer, <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> pe)
<a name="l00523"></a>00523 {
<a name="l00524"></a>00524     <span class="keywordflow">if</span> (layer &gt;= <a class="code" href="class_neural_net.html#a0e202814817d8acf923bbb8481a79e11" title="Number of layers.">layers</a> || pe &gt;= <a class="code" href="class_neural_net.html#ae3f57ff94e97b1b04f49787b58cf2f80" title="For internal use, this count includes bias units.">elements</a>[layer])
<a name="l00525"></a>00525         <span class="keywordflow">return</span>(-1.0f);
<a name="l00526"></a>00526 
<a name="l00527"></a>00527     <span class="keywordflow">return</span>(<a class="code" href="class_neural_net.html#af2ba1bf36dda0676496d3f8a5c5cac52" title="Neuron layers.">PElement</a>[layer][pe]-&gt;output);
<a name="l00528"></a>00528 };
<a name="l00530"></a>00530 
<a name="l00531"></a>00531 
<a name="l00533"></a>00533 <span class="comment">//      Get all of the output layer&#39;s values.</span>
<a name="l00534"></a>00534 <span class="comment">//      The double array must be large enough to hold all of the values.</span>
<a name="l00535"></a>00535 <span class="comment">//</span>
<a name="l00536"></a>00536 
<a name="l00537"></a><a class="code" href="class_neural_net.html#a59b7461dd4a5c0fef70fcf3841ab20ae">00537</a> <span class="keywordtype">int</span> <a class="code" href="class_neural_net.html#a59b7461dd4a5c0fef70fcf3841ab20ae" title="Return outputs from output layer - array must be large enough.">NeuralNet::GetFinalOutputs</a>(<span class="keywordtype">double</span> *outputs)
<a name="l00538"></a>00538 {
<a name="l00539"></a>00539     <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> pe;
<a name="l00540"></a>00540 
<a name="l00541"></a>00541     <span class="keywordflow">if</span> (!outputs)
<a name="l00542"></a>00542         <span class="keywordflow">return</span>(-1);
<a name="l00543"></a>00543 
<a name="l00544"></a>00544     <span class="keywordflow">for</span>(pe = 0; pe &lt; <a class="code" href="class_neural_net.html#ae3f57ff94e97b1b04f49787b58cf2f80" title="For internal use, this count includes bias units.">elements</a>[<a class="code" href="class_neural_net.html#af3c63ff1bfa0968e10ee9a894b45ae2e" title="Shortcut which is equal (layers - 1)">sublayer</a>]; pe++)
<a name="l00545"></a>00545         outputs[pe] = <a class="code" href="class_neural_net.html#af2ba1bf36dda0676496d3f8a5c5cac52" title="Neuron layers.">PElement</a>[<a class="code" href="class_neural_net.html#af3c63ff1bfa0968e10ee9a894b45ae2e" title="Shortcut which is equal (layers - 1)">sublayer</a>][pe]-&gt;output;
<a name="l00546"></a>00546 
<a name="l00547"></a>00547     <span class="keywordflow">return</span>(0);
<a name="l00548"></a>00548 };
<a name="l00550"></a>00550 
<a name="l00551"></a>00551 
<a name="l00552"></a>00552 
<a name="l00554"></a>00554 <span class="comment">//    Get all of output layer&#39;s output, telling neurons to scale them out</span>
<a name="l00555"></a>00555 <span class="comment">//    double array must be large enough to hold all values</span>
<a name="l00556"></a>00556 <span class="comment">//</span>
<a name="l00557"></a>00557 
<a name="l00558"></a><a class="code" href="class_neural_net.html#afd27b3d90e71818c394dc4ff0e67bdae">00558</a> <span class="keywordtype">int</span> <a class="code" href="class_neural_net.html#afd27b3d90e71818c394dc4ff0e67bdae" title="Return outputs from output layer, scaled to our dimensions.">NeuralNet::GetFinalOutputsScaled</a>(<span class="keywordtype">double</span> *outputs)
<a name="l00559"></a>00559 {
<a name="l00560"></a>00560     <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> pe;
<a name="l00561"></a>00561 
<a name="l00562"></a>00562     <span class="keywordflow">if</span> (!outputs)
<a name="l00563"></a>00563         <span class="keywordflow">return</span>(-1);
<a name="l00564"></a>00564 
<a name="l00565"></a>00565     <span class="keywordflow">for</span>(pe = 0; pe &lt; <a class="code" href="class_neural_net.html#ae3f57ff94e97b1b04f49787b58cf2f80" title="For internal use, this count includes bias units.">elements</a>[<a class="code" href="class_neural_net.html#af3c63ff1bfa0968e10ee9a894b45ae2e" title="Shortcut which is equal (layers - 1)">sublayer</a>]; pe++)
<a name="l00566"></a>00566         outputs[pe] = <a class="code" href="class_neural_net.html#af2ba1bf36dda0676496d3f8a5c5cac52" title="Neuron layers.">PElement</a>[<a class="code" href="class_neural_net.html#af3c63ff1bfa0968e10ee9a894b45ae2e" title="Shortcut which is equal (layers - 1)">sublayer</a>][pe]-&gt;ScaleOut();
<a name="l00567"></a>00567 
<a name="l00568"></a>00568     <span class="keywordflow">return</span>(0);
<a name="l00569"></a>00569 };
<a name="l00571"></a>00571 
<a name="l00572"></a>00572 
<a name="l00573"></a>00573 
<a name="l00575"></a>00575 <span class="comment">//     Set all inputs</span>
<a name="l00576"></a>00576 <span class="comment">//</span>
<a name="l00577"></a>00577 
<a name="l00578"></a><a class="code" href="class_neural_net.html#ad1e933de6be8d8402f1db623fa2adec8">00578</a> <span class="keywordtype">int</span> <a class="code" href="class_neural_net.html#ad1e933de6be8d8402f1db623fa2adec8" title="Set the inputs.">NeuralNet::SetInputs</a>(<span class="keywordtype">double</span> *inputs)
<a name="l00579"></a>00579 {
<a name="l00580"></a>00580     <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> pe;
<a name="l00581"></a>00581     <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> els;
<a name="l00582"></a>00582 
<a name="l00583"></a>00583     <span class="keywordflow">if</span> (!inputs)
<a name="l00584"></a>00584         <span class="keywordflow">return</span>(-1);
<a name="l00585"></a>00585 
<a name="l00586"></a>00586     els = <a class="code" href="class_neural_net.html#ae3f57ff94e97b1b04f49787b58cf2f80" title="For internal use, this count includes bias units.">elements</a>[0] - 1;
<a name="l00587"></a>00587     <span class="keywordflow">for</span>(pe = 0; pe &lt; els; pe++)
<a name="l00588"></a>00588         <a class="code" href="class_neural_net.html#ae2b80df9ee9a517e7ef66cd675c45272" title="Set neuron output (for input layer)">SetNeuronOutput</a>(0, pe, inputs[pe]);
<a name="l00589"></a>00589 
<a name="l00590"></a>00590     <span class="keywordflow">return</span>(0);
<a name="l00591"></a>00591 };
<a name="l00593"></a>00593 
<a name="l00594"></a>00594 
<a name="l00595"></a>00595 
<a name="l00596"></a>00596 
<a name="l00598"></a>00598 <span class="comment">//     Set all inputs and then tell the neurons to scale them in</span>
<a name="l00599"></a>00599 <span class="comment">//</span>
<a name="l00600"></a>00600 
<a name="l00601"></a><a class="code" href="class_neural_net.html#ae501bf1aa2e087e70b45a6245282e560">00601</a> <span class="keywordtype">int</span> <a class="code" href="class_neural_net.html#ae501bf1aa2e087e70b45a6245282e560" title="Set all inputs and tell neurons to scale them.">NeuralNet::SetInputsScaled</a>(<span class="keywordtype">double</span> *inputs)
<a name="l00602"></a>00602 {
<a name="l00603"></a>00603     <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> pe;
<a name="l00604"></a>00604     <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> els;
<a name="l00605"></a>00605 
<a name="l00606"></a>00606     <span class="keywordflow">if</span> (!inputs)
<a name="l00607"></a>00607         <span class="keywordflow">return</span>(-1);
<a name="l00608"></a>00608 
<a name="l00609"></a>00609     els = <a class="code" href="class_neural_net.html#ae3f57ff94e97b1b04f49787b58cf2f80" title="For internal use, this count includes bias units.">elements</a>[0] - 1;
<a name="l00610"></a>00610     <span class="keywordflow">for</span>(pe = 0; pe &lt; els; pe++)
<a name="l00611"></a>00611         <a class="code" href="class_neural_net.html#a61a8ac4522b7a92a0fd1277f55512ff0" title="Set neuron output (for input layer) and tell neuron to scale it.">SetNeuronOutputScaled</a>(0, pe, inputs[pe]);
<a name="l00612"></a>00612 
<a name="l00613"></a>00613     <span class="keywordflow">return</span>(0);
<a name="l00614"></a>00614 };
<a name="l00616"></a>00616 
<a name="l00617"></a>00617 
<a name="l00618"></a>00618 
<a name="l00620"></a>00620 <span class="comment">//  Scale neurons to minimums and maximums</span>
<a name="l00621"></a>00621 <span class="comment">//</span>
<a name="l00622"></a>00622 <span class="comment">//  Outputs must be between 0 and 1, but a good input range would be between 0 and 3</span>
<a name="l00623"></a>00623 <span class="comment">//</span>
<a name="l00624"></a>00624 <span class="comment">//      The best scaling is accomplished by subtracting the mean and dividing by </span>
<a name="l00625"></a>00625 <span class="comment">//      the standard deviation.</span>
<a name="l00626"></a>00626 <span class="comment">//</span>
<a name="l00627"></a>00627 
<a name="l00628"></a><a class="code" href="class_neural_net.html#abdbf58878440e1627749a9ee6b7f95be">00628</a> <span class="keywordtype">bool</span> <a class="code" href="class_neural_net.html#abdbf58878440e1627749a9ee6b7f95be" title="Get scaling factors (offset and scale) for inputs and outputs.">NeuralNet::ScaleNeurons</a>(<a class="code" href="_trainset_8h.html#add47e64e18b5701a55eea23c7b04c696">TRAINSET_VEC</a> &amp;vTrainSet)
<a name="l00629"></a>00629 {
<a name="l00630"></a>00630     <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> uIndex; <span class="comment">// An index</span>
<a name="l00631"></a>00631     <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> uSet; <span class="comment">// Sets</span>
<a name="l00632"></a>00632     <span class="keywordtype">double</span> dMean;
<a name="l00633"></a>00633     <span class="keywordtype">double</span> dStdDev;
<a name="l00634"></a>00634     <a class="code" href="_network_8h.html#a37c6fa5e58761c6a13961ef8c38f92b1">DOUBLE_VEC</a> vWork;
<a name="l00635"></a>00635     <span class="keywordtype">double</span> dWork;
<a name="l00636"></a>00636 
<a name="l00637"></a>00637     <span class="comment">// Initialize</span>
<a name="l00638"></a>00638     <a class="code" href="class_neural_net.html#ab731e89f294639ee1de018a02204d47e">vInputMean</a>.clear();
<a name="l00639"></a>00639     <a class="code" href="class_neural_net.html#abcbc27b95edbba0f3a0b0be9caeea104" title="Save the standard deviation for all outputs.">vInputStdDev</a>.clear();
<a name="l00640"></a>00640     <a class="code" href="class_neural_net.html#a87b0d2e664dda7def01e437cd1c69028" title="Save the mean for all outputs.">vOutputMean</a>.clear();
<a name="l00641"></a>00641     <a class="code" href="class_neural_net.html#af80ee309cb980881a48a2b06ec8ec94c" title="Save the standard deviation for all outputs.">vOutputStdDev</a>.clear();
<a name="l00642"></a>00642 
<a name="l00643"></a>00643     <span class="comment">// Find the mean and std dev for each input column</span>
<a name="l00644"></a>00644     <span class="comment">// For each column . . .</span>
<a name="l00645"></a>00645     <span class="keywordflow">for</span>(uIndex = 0; uIndex &lt; <a class="code" href="class_neural_net.html#abeb6e703d60a6dbe3a979aa168d8ea1a" title="For external use.">pelements</a>[0]; uIndex++)
<a name="l00646"></a>00646     { <span class="comment">// Collect the column for each set (epoch)</span>
<a name="l00647"></a>00647         vWork.clear();
<a name="l00648"></a>00648         <span class="keywordflow">for</span>(uSet = 0; uSet &lt; (<span class="keywordtype">unsigned</span> int) vTrainSet.size(); uSet++)
<a name="l00649"></a>00649             vWork.push_back(vTrainSet[uSet]-&gt;dInputs[uIndex]);
<a name="l00650"></a>00650         <span class="comment">// Get the mean and std deviation for this column</span>
<a name="l00651"></a>00651         <span class="keywordflow">if</span> (!<a class="code" href="class_neural_net.html#af724082463d1be4d552471f4edf56d62" title="Calculate the standard deviation.">CalculateStandardDeviation</a>(vWork, dMean, dStdDev))
<a name="l00652"></a>00652             <span class="keywordflow">return</span>(<span class="keyword">false</span>);
<a name="l00653"></a>00653         <span class="comment">// Save the results</span>
<a name="l00654"></a>00654         <span class="keywordflow">if</span> (dStdDev == 0.0f)
<a name="l00655"></a>00655             dStdDev = 0.01f;
<a name="l00656"></a>00656         <a class="code" href="class_neural_net.html#ab731e89f294639ee1de018a02204d47e">vInputMean</a>.push_back(dMean);
<a name="l00657"></a>00657         <a class="code" href="class_neural_net.html#abcbc27b95edbba0f3a0b0be9caeea104" title="Save the standard deviation for all outputs.">vInputStdDev</a>.push_back(dStdDev);
<a name="l00658"></a>00658         <span class="comment">// Scale the inputs for this column and save as part of the training sets</span>
<a name="l00659"></a>00659         <span class="keywordflow">for</span>(uSet = 0; uSet &lt; (<span class="keywordtype">unsigned</span> int) vTrainSet.size(); uSet++)
<a name="l00660"></a>00660         {
<a name="l00661"></a>00661             dWork = vTrainSet[uSet]-&gt;dInputs[uIndex] - dMean;
<a name="l00662"></a>00662             dWork /= dStdDev;
<a name="l00663"></a>00663             dWork += 3; <span class="comment">// So make them all positive</span>
<a name="l00664"></a>00664             dWork /= 2; <span class="comment">// and between 0 and 3</span>
<a name="l00665"></a>00665             <span class="keywordflow">if</span> (dWork &lt; 0)
<a name="l00666"></a>00666                 dWork = 0;
<a name="l00667"></a>00667             vTrainSet[uSet]-&gt;dScaledInputs[uIndex] = dWork;
<a name="l00668"></a>00668         };
<a name="l00669"></a>00669     };
<a name="l00670"></a>00670 
<a name="l00671"></a>00671     <span class="comment">// Find the mean and std dev for each output column</span>
<a name="l00672"></a>00672     <span class="comment">// For each column</span>
<a name="l00673"></a>00673     <span class="keywordflow">for</span>(uIndex = 0; uIndex &lt; pelements[<a class="code" href="class_neural_net.html#a0e202814817d8acf923bbb8481a79e11" title="Number of layers.">layers</a> - 1]; uIndex++)
<a name="l00674"></a>00674     { <span class="comment">// Collect the column for each set (epoch)</span>
<a name="l00675"></a>00675         vWork.clear();
<a name="l00676"></a>00676         <span class="keywordflow">for</span>(uSet = 0; uSet &lt; (<span class="keywordtype">unsigned</span> int) vTrainSet.size(); uSet++)
<a name="l00677"></a>00677             vWork.push_back(vTrainSet[uSet]-&gt;dOutputs[uIndex]);
<a name="l00678"></a>00678         <span class="comment">// Get the mean and std deviation for this column</span>
<a name="l00679"></a>00679         <span class="keywordflow">if</span> (!<a class="code" href="class_neural_net.html#af724082463d1be4d552471f4edf56d62" title="Calculate the standard deviation.">CalculateStandardDeviation</a>(vWork, dMean, dStdDev))
<a name="l00680"></a>00680             <span class="keywordflow">return</span>(<span class="keyword">false</span>);
<a name="l00681"></a>00681         <span class="comment">// Save the results</span>
<a name="l00682"></a>00682         <span class="keywordflow">if</span> (dStdDev == 0.0f)
<a name="l00683"></a>00683             dStdDev = 0.01f;
<a name="l00684"></a>00684         <a class="code" href="class_neural_net.html#a87b0d2e664dda7def01e437cd1c69028" title="Save the mean for all outputs.">vOutputMean</a>.push_back(dMean);
<a name="l00685"></a>00685         <a class="code" href="class_neural_net.html#af80ee309cb980881a48a2b06ec8ec94c" title="Save the standard deviation for all outputs.">vOutputStdDev</a>.push_back(dStdDev);
<a name="l00686"></a>00686         <span class="comment">// Scale the outputs for this column and save as part of the training sets</span>
<a name="l00687"></a>00687         <span class="keywordflow">for</span>(uSet = 0; uSet &lt; (<span class="keywordtype">unsigned</span> int) vTrainSet.size(); uSet++)
<a name="l00688"></a>00688         {
<a name="l00689"></a>00689             dWork = vTrainSet[uSet]-&gt;dOutputs[uIndex] - dMean;
<a name="l00690"></a>00690             dWork /= dStdDev; <span class="comment">// This gives a result about -3 to +3</span>
<a name="l00691"></a>00691             dWork += 3; <span class="comment">// So make them all positive</span>
<a name="l00692"></a>00692             dWork /= 6; <span class="comment">// and between 0 and .999999</span>
<a name="l00693"></a>00693             <span class="keywordflow">if</span> (dWork &lt; 0)
<a name="l00694"></a>00694                 dWork = 0;
<a name="l00695"></a>00695             <span class="keywordflow">if</span> (dWork &gt; 1.0f)
<a name="l00696"></a>00696                 dWork = 1.0f;
<a name="l00697"></a>00697             vTrainSet[uSet]-&gt;dScaledOutputs[uIndex] = dWork;
<a name="l00698"></a>00698         };
<a name="l00699"></a>00699     };
<a name="l00700"></a>00700 
<a name="l00701"></a>00701     <span class="keywordflow">return</span>(<span class="keyword">true</span>);
<a name="l00702"></a>00702 };
<a name="l00704"></a>00704 
<a name="l00705"></a>00705 
<a name="l00707"></a>00707 <span class="comment">//     Process inputs in this array.  Layer 0 is input layer</span>
<a name="l00708"></a>00708 <span class="comment">//</span>
<a name="l00709"></a>00709 
<a name="l00710"></a><a class="code" href="class_neural_net.html#a8e0c439cf86f7fcb0b4e0699ea86e445">00710</a> <span class="keywordtype">int</span> <a class="code" href="class_neural_net.html#a8e0c439cf86f7fcb0b4e0699ea86e445" title="Process these inputs.">NeuralNet::ProcessInputs</a>(<span class="keywordtype">double</span> *inputs)
<a name="l00711"></a>00711 {
<a name="l00712"></a>00712     <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> pe;
<a name="l00713"></a>00713     <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> els;
<a name="l00714"></a>00714 
<a name="l00715"></a>00715     <span class="keywordflow">if</span> (!inputs)
<a name="l00716"></a>00716         <span class="keywordflow">return</span>(-1);
<a name="l00717"></a>00717 
<a name="l00718"></a>00718     els = <a class="code" href="class_neural_net.html#ae3f57ff94e97b1b04f49787b58cf2f80" title="For internal use, this count includes bias units.">elements</a>[0] - 1;
<a name="l00719"></a>00719     <span class="keywordflow">for</span>(pe = 0; pe &lt; els; pe++)
<a name="l00720"></a>00720         <a class="code" href="class_neural_net.html#ae2b80df9ee9a517e7ef66cd675c45272" title="Set neuron output (for input layer)">SetNeuronOutput</a>(0, pe, inputs[pe]);
<a name="l00721"></a>00721 
<a name="l00722"></a>00722     <a class="code" href="class_neural_net.html#a5c9bad870ae3ab6bc2af8c1bad136bb8" title="Process the data if input layer is loaded with SetNeuronOutput.">ProcessData</a>();
<a name="l00723"></a>00723 
<a name="l00724"></a>00724     <span class="keywordflow">return</span>(0);
<a name="l00725"></a>00725 };
<a name="l00727"></a>00727 
<a name="l00728"></a>00728 
<a name="l00729"></a>00729 
<a name="l00730"></a>00730 
<a name="l00732"></a>00732 <span class="comment">//     Process data already plcaed in the input layer outputs.</span>
<a name="l00733"></a>00733 <span class="comment">//</span>
<a name="l00734"></a>00734 
<a name="l00735"></a><a class="code" href="class_neural_net.html#a5c9bad870ae3ab6bc2af8c1bad136bb8">00735</a> <span class="keywordtype">void</span> <a class="code" href="class_neural_net.html#a5c9bad870ae3ab6bc2af8c1bad136bb8" title="Process the data if input layer is loaded with SetNeuronOutput.">NeuralNet::ProcessData</a>()
<a name="l00736"></a>00736 {
<a name="l00737"></a>00737     <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> layer;
<a name="l00738"></a>00738     <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> pe;
<a name="l00739"></a>00739 
<a name="l00740"></a>00740     <span class="comment">// For each layer of neurons after the input layer</span>
<a name="l00741"></a>00741     <span class="keywordflow">for</span>(layer = 1; layer &lt; <a class="code" href="class_neural_net.html#a0e202814817d8acf923bbb8481a79e11" title="Number of layers.">layers</a>; layer++)
<a name="l00742"></a>00742     { <span class="comment">// For each neuron in layer</span>
<a name="l00743"></a>00743         <span class="keywordflow">for</span>(pe = 0; pe &lt; <a class="code" href="class_neural_net.html#ae3f57ff94e97b1b04f49787b58cf2f80" title="For internal use, this count includes bias units.">elements</a>[layer]; pe++)
<a name="l00744"></a>00744         { <span class="comment">// Process all outputs from previous layer</span>
<a name="l00745"></a>00745             <a class="code" href="class_neural_net.html#af2ba1bf36dda0676496d3f8a5c5cac52" title="Neuron layers.">PElement</a>[layer][pe]-&gt;<a class="code" href="class_neuron.html#a66460702cb8222e2e9b959634fdc0281" title="Combine inputs.">CalculateOutput</a>(<a class="code" href="class_neural_net.html#af2ba1bf36dda0676496d3f8a5c5cac52" title="Neuron layers.">PElement</a>[layer - 1]);
<a name="l00746"></a>00746         };
<a name="l00747"></a>00747         <span class="comment">// Make sure all threads are done</span>
<a name="l00748"></a>00748         <span class="keywordflow">if</span> (layer &lt; <a class="code" href="class_neural_net.html#af3c63ff1bfa0968e10ee9a894b45ae2e" title="Shortcut which is equal (layers - 1)">sublayer</a>)
<a name="l00749"></a>00749             <a class="code" href="class_neural_net.html#af2ba1bf36dda0676496d3f8a5c5cac52" title="Neuron layers.">PElement</a>[layer][elements[layer] - 1]-&gt;<a class="code" href="class_neuron.html#ab1583b0659eb2189fe0fd20b4af2ddb3" title="Actual output.">output</a> = 1.0F;
<a name="l00750"></a>00750     };
<a name="l00751"></a>00751 };
<a name="l00753"></a>00753 
<a name="l00754"></a>00754 
<a name="l00755"></a>00755 
<a name="l00757"></a>00757 <span class="comment">//    Train the net, use the correct training algorithm</span>
<a name="l00758"></a>00758 <span class="comment">//</span>
<a name="l00759"></a>00759 
<a name="l00760"></a><a class="code" href="class_neural_net.html#a5dcc92d3f13f2fd4df98c1fdb47cda51">00760</a> <span class="keywordtype">void</span> <a class="code" href="class_neural_net.html#a5dcc92d3f13f2fd4df98c1fdb47cda51" title="Train the network, pass in a vector of structures.">NeuralNet::Train</a>(<a class="code" href="_trainset_8h.html#add47e64e18b5701a55eea23c7b04c696">TRAINSET_VEC</a> &amp;vTrainSet, <span class="keywordtype">int</span> <span class="keyword">volatile</span> *iTrain)
<a name="l00761"></a>00761 {
<a name="l00762"></a>00762     <a class="code" href="class_neural_net.html#a6e200122a6165c503741b9d54b735e22" title="Use the RProp algorithm for training.">bUseRProp</a> ? <a class="code" href="class_neural_net.html#a06501416a2651d603de5edc8ce764163" title="Train the network.">TrainRProp</a>(vTrainSet, iTrain) : <a class="code" href="class_neural_net.html#aae91d67dc866d6d9cfcf1ba1793f149b" title="Train the network.">TrainBackProp</a>(vTrainSet, iTrain);
<a name="l00763"></a>00763 };
<a name="l00765"></a>00765 
<a name="l00766"></a>00766 
<a name="l00767"></a>00767 
<a name="l00769"></a>00769 <span class="comment">//  Train the network, pass in an array of structures</span>
<a name="l00771"></a>00771 <span class="comment"></span>
<a name="l00772"></a><a class="code" href="class_neural_net.html#abe65c8e14611d01e8af6e20b73148fab">00772</a> <span class="keywordtype">void</span> <a class="code" href="class_neural_net.html#a5dcc92d3f13f2fd4df98c1fdb47cda51" title="Train the network, pass in a vector of structures.">NeuralNet::Train</a>(<span class="keyword">struct</span> <a class="code" href="structs_train_set.html">sTrainSet</a> **pTrainSet, <span class="keywordtype">int</span> iSize, <span class="keywordtype">int</span> <span class="keyword">volatile</span> *iTrain)
<a name="l00773"></a>00773 {
<a name="l00774"></a>00774     <a class="code" href="_trainset_8h.html#add47e64e18b5701a55eea23c7b04c696">TRAINSET_VEC</a> vTrainSet;
<a name="l00775"></a>00775 
<a name="l00776"></a>00776     <span class="comment">// Create our own TRAINSET_VEC and pass it to the overloaded Train method</span>
<a name="l00777"></a>00777     <span class="keywordflow">for</span>(<span class="keywordtype">int</span> iX = 0; iX &lt; iSize; iX++)
<a name="l00778"></a>00778         vTrainSet.push_back(pTrainSet[iX]);
<a name="l00779"></a>00779 
<a name="l00780"></a>00780     <a class="code" href="class_neural_net.html#a5dcc92d3f13f2fd4df98c1fdb47cda51" title="Train the network, pass in a vector of structures.">Train</a>(vTrainSet, iTrain);
<a name="l00781"></a>00781 };
<a name="l00783"></a>00783 
<a name="l00784"></a>00784 
<a name="l00786"></a>00786 <span class="comment">//      Learn by using Resilient Back Propagation.</span>
<a name="l00787"></a>00787 <span class="comment">//  Inputs must be set by SetNeuronOutput prior to doing this.</span>
<a name="l00788"></a>00788 <span class="comment">//</span>
<a name="l00789"></a>00789 <span class="comment">//      NOTE: Since outputs     are scaled to 0 to 1, the allowable error is actually a</span>
<a name="l00790"></a>00790 <span class="comment">//                percentage of the output.  For example, if the range of an output is</span>
<a name="l00791"></a>00791 <span class="comment">//                10 (0 to 10), then the actual output after training for a result of 5</span>
<a name="l00792"></a>00792 <span class="comment">//        with an allowable error of .05 (5%) could be from 4.5 to 5.5, </span>
<a name="l00793"></a>00793 <span class="comment">//                5 +- (.05 * 10).  However, note that the &quot;total error&quot; is the sum</span>
<a name="l00794"></a>00794 <span class="comment">//                of all errors in the epoch (set), so in practice an individual error </span>
<a name="l00795"></a>00795 <span class="comment">//                is rarely that high.</span>
<a name="l00796"></a>00796 <span class="comment">//</span>
<a name="l00797"></a>00797 <span class="comment">//      Note that when using Rprop, we use &quot;epoch&quot; or &quot;batch&quot; learning, </span>
<a name="l00798"></a>00798 <span class="comment">//      i.e. we adjust the weights after all patterns in the set are calculated.</span>
<a name="l00799"></a>00799 <span class="comment">//      As such, we calculate the error here, but adjust the weights later.</span>
<a name="l00800"></a>00800 <span class="comment">//</span>
<a name="l00801"></a>00801 
<a name="l00802"></a><a class="code" href="class_neural_net.html#a9bc60b6b5ae4b8a95bad94698c68cc43">00802</a> <span class="keywordtype">void</span> <a class="code" href="class_neural_net.html#a9bc60b6b5ae4b8a95bad94698c68cc43" title="For each layer.">NeuralNet::LearnRProp</a>(<span class="keywordtype">double</span> *target)
<a name="l00803"></a>00803 {
<a name="l00804"></a>00804     <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> layer;
<a name="l00805"></a>00805     <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> pe;
<a name="l00806"></a>00806     <span class="keywordtype">double</span> dTarget;
<a name="l00807"></a>00807 
<a name="l00808"></a>00808     <span class="comment">// Process loaded inputs</span>
<a name="l00809"></a>00809     <a class="code" href="class_neural_net.html#a5c9bad870ae3ab6bc2af8c1bad136bb8" title="Process the data if input layer is loaded with SetNeuronOutput.">ProcessData</a>();
<a name="l00810"></a>00810 
<a name="l00811"></a>00811     <span class="comment">// Back propagate starting with the output layer</span>
<a name="l00812"></a>00812     layer = <a class="code" href="class_neural_net.html#af3c63ff1bfa0968e10ee9a894b45ae2e" title="Shortcut which is equal (layers - 1)">sublayer</a>;
<a name="l00813"></a>00813 
<a name="l00814"></a>00814     <span class="comment">// Calculate the error weight (EW)</span>
<a name="l00815"></a>00815     <span class="keywordflow">for</span>(pe = 0; pe &lt; <a class="code" href="class_neural_net.html#ae3f57ff94e97b1b04f49787b58cf2f80" title="For internal use, this count includes bias units.">elements</a>[layer]; pe++)
<a name="l00816"></a>00816     {
<a name="l00817"></a>00817         dTarget = target[pe];
<a name="l00818"></a>00818 
<a name="l00819"></a>00819         <a class="code" href="class_neural_net.html#af2ba1bf36dda0676496d3f8a5c5cac52" title="Neuron layers.">PElement</a>[layer][pe]-&gt;<a class="code" href="class_neuron.html#a91aa5034ce15b1e434705121a3169df6" title="Calculate error weight for outer layer - RProp.">CalculateOuterEWRProp</a>(dTarget, <a class="code" href="class_neural_net.html#af2ba1bf36dda0676496d3f8a5c5cac52" title="Neuron layers.">PElement</a>[layer - 1]);
<a name="l00820"></a>00820 
<a name="l00821"></a>00821         <span class="comment">// This is &quot;more correct&quot;</span>
<a name="l00822"></a>00822         <a class="code" href="class_neural_net.html#a3d8aa2fd8788831b334b8fbf5cec26b4" title="Total error.">total_error</a> += <a class="code" href="class_neural_net.html#af2ba1bf36dda0676496d3f8a5c5cac52" title="Neuron layers.">PElement</a>[layer][pe]-&gt;<a class="code" href="class_neuron.html#afd7da28bcf28a83b95dea4d6b4a38ce0" title="Error derivative.">ea</a> * <a class="code" href="class_neural_net.html#af2ba1bf36dda0676496d3f8a5c5cac52" title="Neuron layers.">PElement</a>[layer][pe]-&gt;<a class="code" href="class_neuron.html#afd7da28bcf28a83b95dea4d6b4a38ce0" title="Error derivative.">ea</a>;
<a name="l00823"></a>00823     };
<a name="l00824"></a>00824 
<a name="l00825"></a>00825     <span class="comment">// Now calculate EWs for hidden layers (not the input layer)</span>
<a name="l00826"></a>00826     <span class="keywordflow">while</span>(--layer) <span class="comment">// Next innermost layer</span>
<a name="l00827"></a>00827     {
<a name="l00828"></a>00828         <span class="keywordflow">for</span>(pe = 0; pe &lt; elements[layer]; pe++)
<a name="l00829"></a>00829         {
<a name="l00830"></a>00830             <a class="code" href="class_neural_net.html#af2ba1bf36dda0676496d3f8a5c5cac52" title="Neuron layers.">PElement</a>[layer][pe]-&gt;<a class="code" href="class_neuron.html#ac54196b8e8a14ee092c13bf624cea925" title="Calculate error weight for hidden layer - RProp.">CalculateHiddenEWRProp</a>(<a class="code" href="class_neural_net.html#af2ba1bf36dda0676496d3f8a5c5cac52" title="Neuron layers.">PElement</a>[layer - 1], <a class="code" href="class_neural_net.html#af2ba1bf36dda0676496d3f8a5c5cac52" title="Neuron layers.">PElement</a>[layer + 1], elements[layer + 1]);
<a name="l00831"></a>00831         };
<a name="l00832"></a>00832     };
<a name="l00833"></a>00833 };
<a name="l00835"></a>00835 
<a name="l00836"></a>00836 
<a name="l00837"></a>00837 
<a name="l00839"></a>00839 <span class="comment">//    RProp training function</span>
<a name="l00840"></a>00840 <span class="comment">//</span>
<a name="l00841"></a>00841 
<a name="l00842"></a><a class="code" href="class_neural_net.html#a06501416a2651d603de5edc8ce764163">00842</a> <span class="keywordtype">void</span> <a class="code" href="class_neural_net.html#a06501416a2651d603de5edc8ce764163" title="Train the network.">NeuralNet::TrainRProp</a>(<a class="code" href="_trainset_8h.html#add47e64e18b5701a55eea23c7b04c696">TRAINSET_VEC</a> &amp;vTrainSet, <span class="keywordtype">int</span> <span class="keyword">volatile</span> *iTrain)
<a name="l00843"></a>00843 {
<a name="l00844"></a>00844     <span class="keywordtype">int</span> iTotalSets;
<a name="l00845"></a>00845     <span class="keywordtype">int</span> iSet;
<a name="l00846"></a>00846     <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> uNeuron;
<a name="l00847"></a>00847     <span class="keyword">struct </span><a class="code" href="structs_train_set.html">sTrainSet</a> *pcTrainSet;
<a name="l00848"></a>00848     <span class="keywordtype">unsigned</span> <span class="keywordtype">long</span> dwElapsed;
<a name="l00849"></a>00849     <span class="keywordtype">unsigned</span> <span class="keywordtype">long</span> dwStart;
<a name="l00850"></a>00850     <span class="keywordtype">long</span> lLastIt;
<a name="l00851"></a>00851 
<a name="l00852"></a>00852     iTotalSets = vTrainSet.size();
<a name="l00853"></a>00853     <span class="keywordflow">if</span> (!iTotalSets)
<a name="l00854"></a>00854         <span class="keywordflow">return</span>;
<a name="l00855"></a>00855 
<a name="l00856"></a>00856     <span class="comment">// Scale the neurons</span>
<a name="l00857"></a>00857     <a class="code" href="class_neural_net.html#abdbf58878440e1627749a9ee6b7f95be" title="Get scaling factors (offset and scale) for inputs and outputs.">ScaleNeurons</a>(vTrainSet);
<a name="l00858"></a>00858 
<a name="l00859"></a>00859     <a class="code" href="class_neural_net.html#ade1f7df3aff13a38ef212ce990774c57" title="Is the net trained.">iTrained</a> = <a class="code" href="_network_8h.html#a696dfa95dff38765b2a37930ff408ea1">TRAINING</a>;
<a name="l00860"></a>00860     <a class="code" href="class_neural_net.html#abda96359ca1b9a39e6202b23d873c9ec" title="Used for RProp weight backtracking.">prev_total_error</a> = <a class="code" href="_network_8h.html#a6b65f4b50d2d129e2fe16f8febc172c4">MAX_DOUBLE</a>;
<a name="l00861"></a>00861     dwStart = <a class="code" href="_neuron_8cpp.html#ad6569deb372fc209034052f030e91ff4">Neuron::GetMilliseconds</a>();
<a name="l00862"></a>00862 
<a name="l00863"></a>00863     lLastIt = 0;
<a name="l00864"></a>00864     <span class="keywordflow">do</span>
<a name="l00865"></a>00865     { <span class="comment">// Start the training process</span>
<a name="l00866"></a>00866         <a class="code" href="class_neural_net.html#a3d8aa2fd8788831b334b8fbf5cec26b4" title="Total error.">total_error</a> = 0.0f;
<a name="l00867"></a>00867         <span class="keywordflow">for</span>(iSet = 0; iSet &lt; iTotalSets; iSet++)
<a name="l00868"></a>00868         { <span class="comment">// For this set . . .</span>
<a name="l00869"></a>00869             pcTrainSet = vTrainSet[iSet];
<a name="l00870"></a>00870             <span class="comment">// Load the inputs</span>
<a name="l00871"></a>00871             <span class="keywordflow">for</span>(uNeuron = 0; uNeuron &lt; <a class="code" href="class_neural_net.html#abeb6e703d60a6dbe3a979aa168d8ea1a" title="For external use.">pelements</a>[0]; uNeuron++)
<a name="l00872"></a>00872                 <a class="code" href="class_neural_net.html#af2ba1bf36dda0676496d3f8a5c5cac52" title="Neuron layers.">PElement</a>[0][uNeuron]-&gt;output = pcTrainSet-&gt;<a class="code" href="structs_train_set.html#a723079fa6e07e405d9e077a0968b5599">dScaledInputs</a>[uNeuron];
<a name="l00873"></a>00873             <span class="comment">// Feed forward and calculate the error                                     </span>
<a name="l00874"></a>00874             <a class="code" href="class_neural_net.html#a9bc60b6b5ae4b8a95bad94698c68cc43" title="For each layer.">LearnRProp</a>(pcTrainSet-&gt;<a class="code" href="structs_train_set.html#ac2ab0b5bfe4e54f59665035f1a01ce90">dScaledOutputs</a>);
<a name="l00875"></a>00875         };
<a name="l00876"></a>00876 
<a name="l00877"></a>00877         <span class="comment">// Get Root Mean Square of error</span>
<a name="l00878"></a>00878         <a class="code" href="class_neural_net.html#a3d8aa2fd8788831b334b8fbf5cec26b4" title="Total error.">total_error</a> /= iTotalSets;
<a name="l00879"></a>00879         <a class="code" href="class_neural_net.html#a3d8aa2fd8788831b334b8fbf5cec26b4" title="Total error.">total_error</a> = ::sqrt(<a class="code" href="class_neural_net.html#a3d8aa2fd8788831b334b8fbf5cec26b4" title="Total error.">total_error</a>);
<a name="l00880"></a>00880 
<a name="l00881"></a>00881         <span class="comment">// Adjust the weights for all training sets (batch or &quot;epoch&quot; mode)</span>
<a name="l00882"></a>00882         <span class="keywordtype">int</span> layer = <a class="code" href="class_neural_net.html#a0e202814817d8acf923bbb8481a79e11" title="Number of layers.">layers</a>;
<a name="l00883"></a>00883         <span class="keywordflow">while</span>(--layer) <span class="comment">// Adjust weights        </span>
<a name="l00884"></a>00884         {
<a name="l00885"></a>00885             <span class="keywordflow">for</span>(<span class="keywordtype">int</span> pe = 0; pe &lt; (int) <a class="code" href="class_neural_net.html#ae3f57ff94e97b1b04f49787b58cf2f80" title="For internal use, this count includes bias units.">elements</a>[layer]; pe++)
<a name="l00886"></a>00886             {
<a name="l00887"></a>00887                 <a class="code" href="class_neural_net.html#af2ba1bf36dda0676496d3f8a5c5cac52" title="Neuron layers.">PElement</a>[layer][pe]-&gt;<a class="code" href="class_neuron.html#a0f72b892161b6571e9cbc8a5b416f9a9" title="Adjust all neuron weights - RProp.">AdjustWeightsRProp</a>(<a class="code" href="class_neural_net.html#af2ba1bf36dda0676496d3f8a5c5cac52" title="Neuron layers.">PElement</a>[layer - 1]);
<a name="l00888"></a>00888             };
<a name="l00889"></a>00889         };
<a name="l00890"></a>00890 
<a name="l00891"></a>00891         <a class="code" href="class_neural_net.html#abda96359ca1b9a39e6202b23d873c9ec" title="Used for RProp weight backtracking.">prev_total_error</a> = <a class="code" href="class_neural_net.html#a3d8aa2fd8788831b334b8fbf5cec26b4" title="Total error.">total_error</a>;
<a name="l00892"></a>00892 
<a name="l00893"></a>00893         <span class="keywordflow">if</span> (*iTrain != <a class="code" href="class_neural_net.html#a799cf3ba0bcc44670824853216af24ebadc2de565d16252787947f7632f99dcfe">START_TRAIN</a>)
<a name="l00894"></a>00894             <span class="keywordflow">break</span>;
<a name="l00895"></a>00895 
<a name="l00896"></a>00896         ++<a class="code" href="class_neural_net.html#a2275579cdf93de684e32e4d2cfb7b3e4" title="How many iterations during training.">lIteration</a>;
<a name="l00897"></a>00897 
<a name="l00898"></a>00898         <span class="comment">// Save &quot;total_error&quot; after each iteration to provide a meaningful </span>
<a name="l00899"></a>00899         <span class="comment">// progress report variable.</span>
<a name="l00900"></a>00900         <a class="code" href="class_neural_net.html#a848726a24e8f86db49a6a2ec54624b7b" title="Saved total error during training for status display.">fErrorDisplay</a> = <a class="code" href="class_neural_net.html#a3d8aa2fd8788831b334b8fbf5cec26b4" title="Total error.">total_error</a>;
<a name="l00901"></a>00901         <a class="code" href="class_neural_net.html#ab5e32443ed80ed7f766f962d018e10b4" title="Update training status. Implement to get a callbeck to display status.">UpdateStatus</a>(<span class="keyword">false</span>, *iTrain);
<a name="l00902"></a>00902     }
<a name="l00903"></a>00903     <span class="keywordflow">while</span>(<a class="code" href="class_neural_net.html#a3d8aa2fd8788831b334b8fbf5cec26b4" title="Total error.">total_error</a> &gt; <a class="code" href="class_neural_net.html#a32c7a3ced047c1d71e99f2c4b51dc14e" title="Allowable error.">error</a>);
<a name="l00904"></a>00904 
<a name="l00905"></a>00905     <span class="keywordflow">if</span> (<a class="code" href="class_neural_net.html#ade1f7df3aff13a38ef212ce990774c57" title="Is the net trained.">iTrained</a> != <a class="code" href="_network_8h.html#a2f050fb6115172bdcd71429bd0822311">UNABLE_TO_CONVERGE</a>)
<a name="l00906"></a>00906         <a class="code" href="class_neural_net.html#ade1f7df3aff13a38ef212ce990774c57" title="Is the net trained.">iTrained</a> = <a class="code" href="class_neural_net.html#a3d8aa2fd8788831b334b8fbf5cec26b4" title="Total error.">total_error</a> &lt;= <a class="code" href="class_neural_net.html#a32c7a3ced047c1d71e99f2c4b51dc14e" title="Allowable error.">error</a> ? <a class="code" href="_network_8h.html#a1ddce05e28402e060aa4f9e3bfe44b52">TRAINED</a> : <a class="code" href="_network_8h.html#ac2b4e44e2f4362b0b6fd020f90087ce1">PARTIALLY_TRAINED</a>;
<a name="l00907"></a>00907 
<a name="l00908"></a>00908     dwElapsed = <a class="code" href="_neuron_8cpp.html#ad6569deb372fc209034052f030e91ff4">Neuron::GetMilliseconds</a>() - dwStart;
<a name="l00909"></a>00909     <a class="code" href="class_neural_net.html#a8e224c79e2b0bb43b9fa3a3e134247b2" title="Total elapsed time.">dwTotalElapsed</a> += dwElapsed;
<a name="l00910"></a>00910 
<a name="l00911"></a>00911     <a class="code" href="class_neural_net.html#ab5e32443ed80ed7f766f962d018e10b4" title="Update training status. Implement to get a callbeck to display status.">UpdateStatus</a>(<span class="keyword">true</span>, *iTrain);
<a name="l00912"></a>00912 };
<a name="l00914"></a>00914 
<a name="l00915"></a>00915 
<a name="l00917"></a>00917 <span class="comment">//      Learn by back propagating.</span>
<a name="l00918"></a>00918 <span class="comment">//  Inputs must be set by SetNeuronOutput prior to doing this.</span>
<a name="l00919"></a>00919 <span class="comment">//</span>
<a name="l00920"></a>00920 
<a name="l00921"></a><a class="code" href="class_neural_net.html#a98fe61e110d512f271a16a7ee12a17c8">00921</a> <span class="keywordtype">void</span> <a class="code" href="class_neural_net.html#a98fe61e110d512f271a16a7ee12a17c8" title="For each layer.">NeuralNet::LearnBackProp</a>(<span class="keywordtype">double</span> *target)
<a name="l00922"></a>00922 {
<a name="l00923"></a>00923     <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> layer;
<a name="l00924"></a>00924     <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> pe;
<a name="l00925"></a>00925     <span class="keywordtype">double</span> dTarget;
<a name="l00926"></a>00926 
<a name="l00927"></a>00927     <span class="comment">// Process loaded inputs</span>
<a name="l00928"></a>00928     <a class="code" href="class_neural_net.html#a5c9bad870ae3ab6bc2af8c1bad136bb8" title="Process the data if input layer is loaded with SetNeuronOutput.">ProcessData</a>();
<a name="l00929"></a>00929 
<a name="l00930"></a>00930     <span class="comment">// Backpropagate starting with the output layer</span>
<a name="l00931"></a>00931     layer = <a class="code" href="class_neural_net.html#af3c63ff1bfa0968e10ee9a894b45ae2e" title="Shortcut which is equal (layers - 1)">sublayer</a>;
<a name="l00932"></a>00932 
<a name="l00933"></a>00933     <span class="comment">// Calculate the error weight (EW)</span>
<a name="l00934"></a>00934     <span class="keywordflow">for</span>(pe = 0; pe &lt; <a class="code" href="class_neural_net.html#ae3f57ff94e97b1b04f49787b58cf2f80" title="For internal use, this count includes bias units.">elements</a>[layer]; pe++)
<a name="l00935"></a>00935     {
<a name="l00936"></a>00936         dTarget = target[pe];
<a name="l00937"></a>00937 
<a name="l00938"></a>00938         <a class="code" href="class_neural_net.html#af2ba1bf36dda0676496d3f8a5c5cac52" title="Neuron layers.">PElement</a>[layer][pe]-&gt;<a class="code" href="class_neuron.html#ac3375bc325a1b84def662961e516c4af" title="Calculate error weight for outer layer - backprop.">CalculateOuterEWBackProp</a>(dTarget, <a class="code" href="class_neural_net.html#af2ba1bf36dda0676496d3f8a5c5cac52" title="Neuron layers.">PElement</a>[layer - 1]);
<a name="l00939"></a>00939 
<a name="l00940"></a>00940         <span class="comment">// This is &quot;more correct&quot;</span>
<a name="l00941"></a>00941         <a class="code" href="class_neural_net.html#a3d8aa2fd8788831b334b8fbf5cec26b4" title="Total error.">total_error</a> += <a class="code" href="class_neural_net.html#af2ba1bf36dda0676496d3f8a5c5cac52" title="Neuron layers.">PElement</a>[layer][pe]-&gt;<a class="code" href="class_neuron.html#afd7da28bcf28a83b95dea4d6b4a38ce0" title="Error derivative.">ea</a> * <a class="code" href="class_neural_net.html#af2ba1bf36dda0676496d3f8a5c5cac52" title="Neuron layers.">PElement</a>[layer][pe]-&gt;<a class="code" href="class_neuron.html#afd7da28bcf28a83b95dea4d6b4a38ce0" title="Error derivative.">ea</a>;
<a name="l00942"></a>00942     };
<a name="l00943"></a>00943 
<a name="l00944"></a>00944     <span class="comment">// Now calculate the EWs for hidden layers (not the input layer)</span>
<a name="l00945"></a>00945     <span class="keywordflow">while</span>(--layer) <span class="comment">// Next innermost layer</span>
<a name="l00946"></a>00946     {
<a name="l00947"></a>00947         <span class="keywordflow">for</span>(pe = 0; pe &lt; elements[layer]; pe++)
<a name="l00948"></a>00948         {
<a name="l00949"></a>00949             <a class="code" href="class_neural_net.html#af2ba1bf36dda0676496d3f8a5c5cac52" title="Neuron layers.">PElement</a>[layer][pe]-&gt;<a class="code" href="class_neuron.html#ac460565ab559b81402581cdba70d9192" title="Calculate error weight for hidden layer - backprop.">CalculateHiddenEWBackProp</a>(<a class="code" href="class_neural_net.html#af2ba1bf36dda0676496d3f8a5c5cac52" title="Neuron layers.">PElement</a>[layer - 1], <a class="code" href="class_neural_net.html#af2ba1bf36dda0676496d3f8a5c5cac52" title="Neuron layers.">PElement</a>[layer + 1], elements[layer + 1]);
<a name="l00950"></a>00950         };
<a name="l00951"></a>00951     };
<a name="l00952"></a>00952 
<a name="l00953"></a>00953     layer = <a class="code" href="class_neural_net.html#a0e202814817d8acf923bbb8481a79e11" title="Number of layers.">layers</a>;
<a name="l00954"></a>00954     <span class="keywordflow">while</span>(--layer) <span class="comment">// Adjust weights</span>
<a name="l00955"></a>00955     {
<a name="l00956"></a>00956         <span class="keywordflow">for</span>(pe = 0; pe &lt; elements[layer]; pe++)
<a name="l00957"></a>00957         {
<a name="l00958"></a>00958             <a class="code" href="class_neural_net.html#af2ba1bf36dda0676496d3f8a5c5cac52" title="Neuron layers.">PElement</a>[layer][pe]-&gt;<a class="code" href="class_neuron.html#a7c28c5e0148a8556b773f056a22d2997" title="Adjust all neuron weights - backprop.">AdjustWeightsBackProp</a>(<a class="code" href="class_neural_net.html#af2ba1bf36dda0676496d3f8a5c5cac52" title="Neuron layers.">PElement</a>[layer - 1], <a class="code" href="class_neural_net.html#a47b081356cece6d51cda1d9a546cf53c" title="Learn rate.">delta</a>);
<a name="l00959"></a>00959         };
<a name="l00960"></a>00960     };
<a name="l00961"></a>00961 };
<a name="l00963"></a>00963 
<a name="l00964"></a>00964 
<a name="l00966"></a>00966 <span class="comment">//    Backprop training function</span>
<a name="l00967"></a>00967 <span class="comment">//</span>
<a name="l00968"></a>00968 
<a name="l00969"></a><a class="code" href="class_neural_net.html#aae91d67dc866d6d9cfcf1ba1793f149b">00969</a> <span class="keywordtype">void</span> <a class="code" href="class_neural_net.html#aae91d67dc866d6d9cfcf1ba1793f149b" title="Train the network.">NeuralNet::TrainBackProp</a>(<a class="code" href="_trainset_8h.html#add47e64e18b5701a55eea23c7b04c696">TRAINSET_VEC</a> &amp;vTrainSet, <span class="keywordtype">int</span> <span class="keyword">volatile</span> *iTrain)
<a name="l00970"></a>00970 {
<a name="l00971"></a>00971     <span class="keywordtype">int</span> iTotalSets;
<a name="l00972"></a>00972     <span class="keywordtype">int</span> iSet;
<a name="l00973"></a>00973     <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> uNeuron;
<a name="l00974"></a>00974     <span class="keyword">struct </span><a class="code" href="structs_train_set.html">sTrainSet</a> *pcTrainSet;
<a name="l00975"></a>00975     <span class="keywordtype">unsigned</span> <span class="keywordtype">long</span> dwElapsed;
<a name="l00976"></a>00976     <span class="keywordtype">unsigned</span> <span class="keywordtype">long</span> dwStart;
<a name="l00977"></a>00977     <span class="keywordtype">long</span> lLastIt;
<a name="l00978"></a>00978 
<a name="l00979"></a>00979     iTotalSets = vTrainSet.size();
<a name="l00980"></a>00980     <span class="keywordflow">if</span> (!iTotalSets)
<a name="l00981"></a>00981         <span class="keywordflow">return</span>;
<a name="l00982"></a>00982 
<a name="l00983"></a>00983     <span class="comment">// Scale the neurons</span>
<a name="l00984"></a>00984     <a class="code" href="class_neural_net.html#abdbf58878440e1627749a9ee6b7f95be" title="Get scaling factors (offset and scale) for inputs and outputs.">ScaleNeurons</a>(vTrainSet);
<a name="l00985"></a>00985 
<a name="l00986"></a>00986     <a class="code" href="class_neural_net.html#ade1f7df3aff13a38ef212ce990774c57" title="Is the net trained.">iTrained</a> = <a class="code" href="_network_8h.html#a696dfa95dff38765b2a37930ff408ea1">TRAINING</a>;
<a name="l00987"></a>00987     dwStart = <a class="code" href="_neuron_8cpp.html#ad6569deb372fc209034052f030e91ff4">Neuron::GetMilliseconds</a>();
<a name="l00988"></a>00988 
<a name="l00989"></a>00989     lLastIt = 0;
<a name="l00990"></a>00990     <span class="keywordflow">do</span>
<a name="l00991"></a>00991     {
<a name="l00992"></a>00992         <a class="code" href="class_neural_net.html#a3d8aa2fd8788831b334b8fbf5cec26b4" title="Total error.">total_error</a> = 0.0f;
<a name="l00993"></a>00993         <span class="keywordflow">for</span>(iSet = 0; iSet &lt; iTotalSets; iSet++)
<a name="l00994"></a>00994         {
<a name="l00995"></a>00995             pcTrainSet = vTrainSet[iSet];
<a name="l00996"></a>00996             <span class="keywordflow">for</span>(uNeuron = 0; uNeuron &lt; <a class="code" href="class_neural_net.html#abeb6e703d60a6dbe3a979aa168d8ea1a" title="For external use.">pelements</a>[0]; uNeuron++)
<a name="l00997"></a>00997                 <a class="code" href="class_neural_net.html#af2ba1bf36dda0676496d3f8a5c5cac52" title="Neuron layers.">PElement</a>[0][uNeuron]-&gt;output = pcTrainSet-&gt;<a class="code" href="structs_train_set.html#a723079fa6e07e405d9e077a0968b5599">dScaledInputs</a>[uNeuron];
<a name="l00998"></a>00998             <a class="code" href="class_neural_net.html#a98fe61e110d512f271a16a7ee12a17c8" title="For each layer.">LearnBackProp</a>(pcTrainSet-&gt;<a class="code" href="structs_train_set.html#ac2ab0b5bfe4e54f59665035f1a01ce90">dScaledOutputs</a>);
<a name="l00999"></a>00999         };
<a name="l01000"></a>01000 
<a name="l01001"></a>01001         <span class="keywordflow">if</span> (*iTrain != <a class="code" href="class_neural_net.html#a799cf3ba0bcc44670824853216af24ebadc2de565d16252787947f7632f99dcfe">START_TRAIN</a>)
<a name="l01002"></a>01002             <span class="keywordflow">break</span>;
<a name="l01003"></a>01003 
<a name="l01004"></a>01004         <span class="comment">// Get Root Mean Square of error</span>
<a name="l01005"></a>01005         <a class="code" href="class_neural_net.html#a3d8aa2fd8788831b334b8fbf5cec26b4" title="Total error.">total_error</a> /= iTotalSets;
<a name="l01006"></a>01006         <a class="code" href="class_neural_net.html#a3d8aa2fd8788831b334b8fbf5cec26b4" title="Total error.">total_error</a> = ::sqrt(<a class="code" href="class_neural_net.html#a3d8aa2fd8788831b334b8fbf5cec26b4" title="Total error.">total_error</a>);
<a name="l01007"></a>01007 
<a name="l01008"></a>01008         ++<a class="code" href="class_neural_net.html#a2275579cdf93de684e32e4d2cfb7b3e4" title="How many iterations during training.">lIteration</a>;
<a name="l01009"></a>01009 
<a name="l01010"></a>01010         <span class="comment">// total_error gets updated per neuron.  Save after each</span>
<a name="l01011"></a>01011         <span class="comment">// iteration to provide a meaningful progress report variable.</span>
<a name="l01012"></a>01012         <a class="code" href="class_neural_net.html#a848726a24e8f86db49a6a2ec54624b7b" title="Saved total error during training for status display.">fErrorDisplay</a> = <a class="code" href="class_neural_net.html#a3d8aa2fd8788831b334b8fbf5cec26b4" title="Total error.">total_error</a>;
<a name="l01013"></a>01013         <a class="code" href="class_neural_net.html#ab5e32443ed80ed7f766f962d018e10b4" title="Update training status. Implement to get a callbeck to display status.">UpdateStatus</a>(<span class="keyword">false</span>, *iTrain);
<a name="l01014"></a>01014     }
<a name="l01015"></a>01015     <span class="keywordflow">while</span>(<a class="code" href="class_neural_net.html#a3d8aa2fd8788831b334b8fbf5cec26b4" title="Total error.">total_error</a> &gt; <a class="code" href="class_neural_net.html#a32c7a3ced047c1d71e99f2c4b51dc14e" title="Allowable error.">error</a>);
<a name="l01016"></a>01016 
<a name="l01017"></a>01017     <span class="keywordflow">if</span> (<a class="code" href="class_neural_net.html#ade1f7df3aff13a38ef212ce990774c57" title="Is the net trained.">iTrained</a> != <a class="code" href="_network_8h.html#a2f050fb6115172bdcd71429bd0822311">UNABLE_TO_CONVERGE</a>)
<a name="l01018"></a>01018         <a class="code" href="class_neural_net.html#ade1f7df3aff13a38ef212ce990774c57" title="Is the net trained.">iTrained</a> = <a class="code" href="class_neural_net.html#a3d8aa2fd8788831b334b8fbf5cec26b4" title="Total error.">total_error</a> &lt;= <a class="code" href="class_neural_net.html#a32c7a3ced047c1d71e99f2c4b51dc14e" title="Allowable error.">error</a> ? <a class="code" href="_network_8h.html#a1ddce05e28402e060aa4f9e3bfe44b52">TRAINED</a> : <a class="code" href="_network_8h.html#ac2b4e44e2f4362b0b6fd020f90087ce1">PARTIALLY_TRAINED</a>;
<a name="l01019"></a>01019 
<a name="l01020"></a>01020     dwElapsed = <a class="code" href="_neuron_8cpp.html#ad6569deb372fc209034052f030e91ff4">Neuron::GetMilliseconds</a>() - dwStart;
<a name="l01021"></a>01021     <a class="code" href="class_neural_net.html#a8e224c79e2b0bb43b9fa3a3e134247b2" title="Total elapsed time.">dwTotalElapsed</a> += dwElapsed;
<a name="l01022"></a>01022 
<a name="l01023"></a>01023     <a class="code" href="class_neural_net.html#ab5e32443ed80ed7f766f962d018e10b4" title="Update training status. Implement to get a callbeck to display status.">UpdateStatus</a>(<span class="keyword">true</span>, *iTrain);
<a name="l01024"></a>01024 };
<a name="l01026"></a>01026 
<a name="l01027"></a>01027 
<a name="l01028"></a>01028 
<a name="l01029"></a>01029 
<a name="l01031"></a>01031 <span class="comment">//     Reset net parameters</span>
<a name="l01032"></a>01032 <span class="comment">//</span>
<a name="l01033"></a>01033 
<a name="l01034"></a><a class="code" href="class_neural_net.html#acfb2b360cab6605468cdd8287b654689">01034</a> <span class="keywordtype">void</span> <a class="code" href="class_neural_net.html#acfb2b360cab6605468cdd8287b654689" title="Reset network parameters.">NeuralNet::ResetNetParameters</a>(<span class="keywordtype">double</span> dError, <span class="keywordtype">double</span> dMomentum,
<a name="l01035"></a>01035     <span class="keywordtype">double</span> dGainf, <span class="keywordtype">double</span> dLearnRate, <span class="keywordtype">bool</span> bRProp)
<a name="l01036"></a>01036 {
<a name="l01037"></a>01037     <a class="code" href="class_neural_net.html#a32c7a3ced047c1d71e99f2c4b51dc14e" title="Allowable error.">error</a> = dError;
<a name="l01038"></a>01038     <a class="code" href="class_neural_net.html#ae2abb290d0c972e07df4a6b8ba37a910" title="Momentum factor.">momentum</a> = dMomentum;
<a name="l01039"></a>01039     <a class="code" href="class_neural_net.html#a1d819b4e7babcd2149f3382afc675090" title="The gain.">dGain</a> = dGainf;
<a name="l01040"></a>01040     <a class="code" href="class_neural_net.html#a47b081356cece6d51cda1d9a546cf53c" title="Learn rate.">delta</a> = dLearnRate;
<a name="l01041"></a>01041     <a class="code" href="class_neural_net.html#a6e200122a6165c503741b9d54b735e22" title="Use the RProp algorithm for training.">bUseRProp</a> = <a class="code" href="class_neural_net.html#a6e200122a6165c503741b9d54b735e22" title="Use the RProp algorithm for training.">bUseRProp</a>;
<a name="l01042"></a>01042 };
<a name="l01044"></a>01044 
<a name="l01045"></a>01045 
<a name="l01046"></a>01046 
<a name="l01047"></a>01047 
<a name="l01048"></a>01048 
<a name="l01050"></a>01050 <span class="comment">//    Get the connections per second</span>
<a name="l01051"></a>01051 <span class="comment">//</span>
<a name="l01052"></a>01052 
<a name="l01053"></a><a class="code" href="class_neural_net.html#a2f60b3fd9979b4cb9846d56cfc3cbb72">01053</a> <span class="keywordtype">unsigned</span> <span class="keywordtype">long</span> <a class="code" href="class_neural_net.html#a2f60b3fd9979b4cb9846d56cfc3cbb72" title="Get the connections/sec.">NeuralNet::GetConnectionsPerSecond</a>()
<a name="l01054"></a>01054 {
<a name="l01055"></a>01055     <span class="keywordflow">return</span>(0);
<a name="l01056"></a>01056 };
<a name="l01058"></a>01058 
<a name="l01059"></a>01059 
<a name="l01060"></a>01060 
<a name="l01061"></a>01061 
<a name="l01063"></a>01063 <span class="comment">//      Get the connections/sec</span>
<a name="l01064"></a>01064 <span class="comment">//</span>
<a name="l01065"></a>01065 
<a name="l01066"></a><a class="code" href="class_neural_net.html#a811564be59727ba946b36fcb9d8d7ffe">01066</a> <span class="keyword">const</span> <span class="keywordtype">char</span> *<a class="code" href="class_neural_net.html#a811564be59727ba946b36fcb9d8d7ffe" title="Get the elapsed time for training.">NeuralNet::GetElapsedTime</a>()
<a name="l01067"></a>01067 {
<a name="l01068"></a>01068     <span class="keywordflow">return</span>(NULL);
<a name="l01069"></a>01069 };
<a name="l01071"></a>01071 
<a name="l01072"></a>01072 
<a name="l01073"></a>01073 
<a name="l01075"></a>01075 <span class="comment">//      Calculate standard deviation</span>
<a name="l01076"></a>01076 <span class="comment">//</span>
<a name="l01077"></a>01077 
<a name="l01078"></a><a class="code" href="class_neural_net.html#af724082463d1be4d552471f4edf56d62">01078</a> <span class="keywordtype">bool</span> <a class="code" href="class_neural_net.html#af724082463d1be4d552471f4edf56d62" title="Calculate the standard deviation.">NeuralNet::CalculateStandardDeviation</a>(<a class="code" href="_network_8h.html#a37c6fa5e58761c6a13961ef8c38f92b1">DOUBLE_VEC</a> &amp;vDoubles, <span class="keywordtype">double</span> &amp;dMean, <span class="keywordtype">double</span> &amp;dStdDev)
<a name="l01079"></a>01079 {
<a name="l01080"></a>01080     <span class="keywordtype">int</span> iX;
<a name="l01081"></a>01081     <span class="keywordtype">double</span> dWork;
<a name="l01082"></a>01082     <span class="keywordtype">int</span> iDataPoints;
<a name="l01083"></a>01083     <span class="keywordtype">double</span> dSum = 0.0f;
<a name="l01084"></a>01084     <span class="keywordtype">double</span> dSST = 0.0f;
<a name="l01085"></a>01085 
<a name="l01086"></a>01086 
<a name="l01087"></a>01087     <span class="comment">// Make sure both have elements</span>
<a name="l01088"></a>01088     <span class="comment">// Save the numner of data points</span>
<a name="l01089"></a>01089     iDataPoints = vDoubles.size();
<a name="l01090"></a>01090 
<a name="l01091"></a>01091     <span class="keywordflow">if</span> (!iDataPoints)
<a name="l01092"></a>01092         <span class="keywordflow">return</span>(<span class="keyword">false</span>);
<a name="l01093"></a>01093 
<a name="l01094"></a>01094     <span class="comment">// Get the sums of the table</span>
<a name="l01095"></a>01095     <span class="keywordflow">for</span>(iX = 0; iX &lt; iDataPoints; iX++)
<a name="l01096"></a>01096         dSum += vDoubles[iX];
<a name="l01097"></a>01097 
<a name="l01098"></a>01098     <span class="comment">// Get the mean of the tables</span>
<a name="l01099"></a>01099     dMean = dSum / iDataPoints;
<a name="l01100"></a>01100 
<a name="l01101"></a>01101     <span class="comment">// Get the Sum of the Squares for each table</span>
<a name="l01102"></a>01102     <span class="keywordflow">for</span>(iX = 0; iX &lt; iDataPoints; iX++)
<a name="l01103"></a>01103         dSST += ((vDoubles[iX] - dMean) * (vDoubles[iX] - dMean));
<a name="l01104"></a>01104 
<a name="l01105"></a>01105     <span class="comment">// Get the standard deviation</span>
<a name="l01106"></a>01106     dWork = dSST / (iDataPoints - 1);
<a name="l01107"></a>01107 
<a name="l01108"></a>01108     dStdDev = ::sqrt(dWork);
<a name="l01109"></a>01109 
<a name="l01110"></a>01110     <span class="keywordflow">return</span>(<span class="keyword">true</span>);
<a name="l01111"></a>01111 };
<a name="l01113"></a>01113 
<a name="l01114"></a>01114 
<a name="l01115"></a>01115 
<a name="l01117"></a>01117 <span class="comment">//    End of: NETWORK.CPP</span>
<a name="l01119"></a>01119 <span class="comment"></span>
<a name="l01120"></a>01120 
<a name="l01121"></a>01121 
<a name="l01122"></a>01122 
</pre></div></div><!-- contents -->
</div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
<a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(0)"><span class="SelectionMark">&#160;</span>All</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(1)"><span class="SelectionMark">&#160;</span>Classes</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(2)"><span class="SelectionMark">&#160;</span>Files</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(3)"><span class="SelectionMark">&#160;</span>Functions</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(4)"><span class="SelectionMark">&#160;</span>Variables</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(5)"><span class="SelectionMark">&#160;</span>Typedefs</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(6)"><span class="SelectionMark">&#160;</span>Enumerator</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(7)"><span class="SelectionMark">&#160;</span>Friends</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(8)"><span class="SelectionMark">&#160;</span>Defines</a></div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

  <div id="nav-path" class="navpath">
    <ul>
      <li class="navelem"><a class="el" href="_network_8cpp.html">Network.cpp</a>      </li>

    <li class="footer">Generated on Sun Feb 24 2013 14:27:42 for nnengine by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.7.6.1 </li>
   </ul>
 </div>


</body>
</html>
