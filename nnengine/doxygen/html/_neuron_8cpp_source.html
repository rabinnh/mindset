<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<title>nnengine: Neuron.cpp Source File</title>

<link href="tabs.css" rel="stylesheet" type="text/css"/>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { searchBox.OnSelectItem(0); });
</script>

</head>
<body>
<div id="top"><!-- do not remove this div! -->


<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  
  
  <td style="padding-left: 0.5em;">
   <div id="projectname">nnengine
   
   </div>
   
  </td>
  
  
  
 </tr>
 </tbody>
</table>
</div>

<!-- Generated by Doxygen 1.7.6.1 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li class="current"><a href="files.html"><span>Files</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
  <div id="navrow2" class="tabs2">
    <ul class="tablist">
      <li><a href="files.html"><span>File&#160;List</span></a></li>
      <li><a href="globals.html"><span>File&#160;Members</span></a></li>
    </ul>
  </div>
</div>
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
  initNavTree('_neuron_8cpp.html','');
</script>
<div id="doc-content">
<div class="header">
  <div class="headertitle">
<div class="title">Neuron.cpp</div>  </div>
</div><!--header-->
<div class="contents">
<a href="_neuron_8cpp.html">Go to the documentation of this file.</a><div class="fragment"><pre class="fragment"><a name="l00001"></a>00001 
<a name="l00002"></a>00002 <span class="comment">//    NEURON.CPP - Neural network processing element </span>
<a name="l00004"></a>00004 <span class="comment"></span><span class="comment">//    Net design notes:</span>
<a name="l00005"></a>00005 <span class="comment">//        For statistical analysis, number of hidden neurons should</span>
<a name="l00006"></a>00006 <span class="comment">//        be about 4 x number of input units.  If there are a</span>
<a name="l00007"></a>00007 <span class="comment">//        sufficient number, more than 1 hidden layer is possible.</span>
<a name="l00008"></a>00008 <span class="comment">//    Total number of weights should be less than number of test</span>
<a name="l00009"></a>00009 <span class="comment">//        patterns * bits required (integer) to represent the data.</span>
<a name="l00010"></a>00010 <span class="comment">//        See pg. 172 of Sept, 1992 Scientific American.</span>
<a name="l00012"></a>00012 <span class="comment"></span>
<a name="l00013"></a>00013 <span class="preprocessor">#include &quot;<a class="code" href="_network_8h.html">Network.h</a>&quot;</span>
<a name="l00014"></a>00014 <span class="preprocessor">#include &quot;<a class="code" href="_neuron_8h.html">Neuron.h</a>&quot;</span>
<a name="l00015"></a>00015 <span class="preprocessor">#include &quot;math.h&quot;</span>
<a name="l00016"></a>00016 <span class="preprocessor">#include &lt;cstdlib&gt;</span>
<a name="l00017"></a>00017 <span class="preprocessor">#include &lt;sys/time.h&gt;</span>
<a name="l00018"></a>00018 
<a name="l00019"></a>00019 <span class="comment">//#define USE_TANH // doesn&#39;t work</span>
<a name="l00020"></a>00020 
<a name="l00021"></a>00021 
<a name="l00023"></a>00023 <span class="comment">//    Neuron constructor</span>
<a name="l00024"></a>00024 <span class="comment">//</span>
<a name="l00025"></a>00025 
<a name="l00026"></a><a class="code" href="class_neuron.html#a4280ce4b2322b75c75a526a8c9059f83">00026</a> <a class="code" href="class_neuron.html#a4280ce4b2322b75c75a526a8c9059f83" title="Constructor.">Neuron::Neuron</a>(<a class="code" href="class_neural_net.html">NeuralNet</a> *AParent, <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> num_inputs, <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> anid)
<a name="l00027"></a>00027 {
<a name="l00028"></a>00028     <span class="comment">// Load values</span>
<a name="l00029"></a>00029     <a class="code" href="class_neuron.html#a4fb2325296966ff19b1a18e9f39e6b72" title="Net we&#39;re a part of.">pNeuralNet</a> = AParent; <span class="comment">// Our net</span>
<a name="l00030"></a>00030     <a class="code" href="class_neuron.html#a04d04b23fae8548335721a06f5a1a6f0" title="Number of inputs.">inputs</a> = num_inputs; <span class="comment">// Number of inputs</span>
<a name="l00031"></a>00031     <a class="code" href="class_neuron.html#ad1a0c0ced35f712cc8ace29898154046" title="Weights.">weights</a> = <span class="keyword">new</span> <span class="keywordtype">double</span>[<a class="code" href="class_neuron.html#a04d04b23fae8548335721a06f5a1a6f0" title="Number of inputs.">inputs</a>]; <span class="comment">// Weights</span>
<a name="l00032"></a>00032     <a class="code" href="class_neuron.html#a0a01e4454838f363f352bcf2315960fe" title="Previous error weight.">prev_ew</a> = <span class="keyword">new</span> <span class="keywordtype">double</span>[<a class="code" href="class_neuron.html#a04d04b23fae8548335721a06f5a1a6f0" title="Number of inputs.">inputs</a>]; <span class="comment">// Current adjustments</span>
<a name="l00033"></a>00033     <a class="code" href="class_neuron.html#a789e0e384caf1cbfb4297acff8ac8fc8" title="Previous change to weight delta.">prev_adj</a> = <span class="keyword">new</span> <span class="keywordtype">double</span>[<a class="code" href="class_neuron.html#a04d04b23fae8548335721a06f5a1a6f0" title="Number of inputs.">inputs</a>]; <span class="comment">// Previous adjustments</span>
<a name="l00034"></a>00034     <a class="code" href="class_neuron.html#a6c1f44d16cb090c34ee5d11f6dd8e215" title="The actual previous change to the weight.">delta_weight</a> = <span class="keyword">new</span> <span class="keywordtype">double</span>[<a class="code" href="class_neuron.html#a04d04b23fae8548335721a06f5a1a6f0" title="Number of inputs.">inputs</a>]; <span class="comment">// Previous weight change</span>
<a name="l00035"></a>00035     <a class="code" href="class_neuron.html#ab346b4b1b16993ccf1fba04f69622582" title="Error weights for each input.">ew</a> = <span class="keyword">new</span> <span class="keywordtype">double</span>[<a class="code" href="class_neuron.html#a04d04b23fae8548335721a06f5a1a6f0" title="Number of inputs.">inputs</a>]; <span class="comment">// Error change</span>
<a name="l00036"></a>00036     <a class="code" href="class_neuron.html#a35050fe1d82011db1336948fb73bab71" title="Rate of error change.">ei</a> = <a class="code" href="class_neuron.html#afd7da28bcf28a83b95dea4d6b4a38ce0" title="Error derivative.">ea</a> = 0.0f; <span class="comment">// Error variables</span>
<a name="l00037"></a>00037     <span class="keywordtype">id</span> = anid; <span class="comment">// Element in the layer</span>
<a name="l00038"></a>00038     <a class="code" href="class_neuron.html#a94560a022ec198c9114a09a8097a89c0" title="Gain for this neuron.">dGain</a> = <a class="code" href="class_neuron.html#a4fb2325296966ff19b1a18e9f39e6b72" title="Net we&#39;re a part of.">pNeuralNet</a>-&gt;<a class="code" href="class_neural_net.html#a1d819b4e7babcd2149f3382afc675090" title="The gain.">dGain</a>; <span class="comment">// Gain is equal to default</span>
<a name="l00039"></a>00039     <a class="code" href="class_neuron.html#a237621505645df1cf40e170ddd47e689" title="Offset for output.">offset</a> = 0;
<a name="l00040"></a>00040 
<a name="l00041"></a>00041     <span class="comment">// Initialize weight deltas</span>
<a name="l00042"></a>00042     <span class="keywordflow">for</span>(<span class="keywordtype">int</span> count = 0; count &lt; (int) <a class="code" href="class_neuron.html#a04d04b23fae8548335721a06f5a1a6f0" title="Number of inputs.">inputs</a>; count++)
<a name="l00043"></a>00043         <a class="code" href="class_neuron.html#a789e0e384caf1cbfb4297acff8ac8fc8" title="Previous change to weight delta.">prev_adj</a>[count] = 0.1f;
<a name="l00044"></a>00044 };
<a name="l00046"></a>00046 
<a name="l00047"></a>00047 
<a name="l00049"></a>00049 <span class="comment">//     Destructor</span>
<a name="l00050"></a>00050 
<a name="l00051"></a><a class="code" href="class_neuron.html#a94a250ce7e167760e593979b899745b1">00051</a> <a class="code" href="class_neuron.html#a94a250ce7e167760e593979b899745b1" title="Destructor.">Neuron::~Neuron</a>()
<a name="l00052"></a>00052 {
<a name="l00053"></a>00053     <span class="keyword">delete</span>[] <a class="code" href="class_neuron.html#ad1a0c0ced35f712cc8ace29898154046" title="Weights.">weights</a>;
<a name="l00054"></a>00054     <span class="keyword">delete</span>[] <a class="code" href="class_neuron.html#a0a01e4454838f363f352bcf2315960fe" title="Previous error weight.">prev_ew</a>;
<a name="l00055"></a>00055     <span class="keyword">delete</span>[] <a class="code" href="class_neuron.html#a789e0e384caf1cbfb4297acff8ac8fc8" title="Previous change to weight delta.">prev_adj</a>;
<a name="l00056"></a>00056     <span class="keyword">delete</span>[] <a class="code" href="class_neuron.html#a6c1f44d16cb090c34ee5d11f6dd8e215" title="The actual previous change to the weight.">delta_weight</a>;
<a name="l00057"></a>00057     <span class="keyword">delete</span>[] <a class="code" href="class_neuron.html#ab346b4b1b16993ccf1fba04f69622582" title="Error weights for each input.">ew</a>;
<a name="l00058"></a>00058 };
<a name="l00060"></a>00060 
<a name="l00061"></a>00061 
<a name="l00063"></a>00063 <span class="comment">//      Randomize the weights in preparation for learning</span>
<a name="l00064"></a>00064 <span class="comment">//</span>
<a name="l00065"></a>00065 
<a name="l00066"></a><a class="code" href="class_neuron.html#adabb156d10fc8f72c0bd65bd4b67d22a">00066</a> <span class="keywordtype">void</span> <a class="code" href="class_neuron.html#adabb156d10fc8f72c0bd65bd4b67d22a" title="Before any training.">Neuron::RandomizeNeuronWeights</a>()
<a name="l00067"></a>00067 {
<a name="l00068"></a>00068     <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> count;
<a name="l00069"></a>00069     <span class="keywordtype">double</span> w;
<a name="l00070"></a>00070 
<a name="l00071"></a>00071     <span class="comment">// Initialize random number generator</span>
<a name="l00072"></a>00072     ::srand(time(NULL));
<a name="l00073"></a>00073 
<a name="l00074"></a>00074     <span class="comment">// Assign weights.  </span>
<a name="l00075"></a>00075     <span class="comment">// The formula for assigning initial weights is -2.4/I &lt; w &gt; 2.4/I where I is # of inputs</span>
<a name="l00076"></a>00076     <span class="keywordflow">for</span>(count = 0; count &lt; <a class="code" href="class_neuron.html#a04d04b23fae8548335721a06f5a1a6f0" title="Number of inputs.">inputs</a>; count++)
<a name="l00077"></a>00077     {
<a name="l00078"></a>00078         w = (double) rand();
<a name="l00079"></a>00079         w = (int) w % 48;
<a name="l00080"></a>00080         w /= 10;
<a name="l00081"></a>00081         w -= 2.4f;
<a name="l00082"></a>00082         w /= <a class="code" href="class_neuron.html#a04d04b23fae8548335721a06f5a1a6f0" title="Number of inputs.">inputs</a>;
<a name="l00083"></a>00083         <a class="code" href="class_neuron.html#ad1a0c0ced35f712cc8ace29898154046" title="Weights.">weights</a>[count] = w;
<a name="l00084"></a>00084         <a class="code" href="class_neuron.html#ab346b4b1b16993ccf1fba04f69622582" title="Error weights for each input.">ew</a>[count] = <a class="code" href="class_neuron.html#a6c1f44d16cb090c34ee5d11f6dd8e215" title="The actual previous change to the weight.">delta_weight</a>[count] = <a class="code" href="class_neuron.html#a0a01e4454838f363f352bcf2315960fe" title="Previous error weight.">prev_ew</a>[count] = 0.0f;
<a name="l00085"></a>00085         <a class="code" href="class_neuron.html#a789e0e384caf1cbfb4297acff8ac8fc8" title="Previous change to weight delta.">prev_adj</a>[count] = 0.1f;
<a name="l00086"></a>00086     };
<a name="l00087"></a>00087 };
<a name="l00089"></a>00089 
<a name="l00090"></a>00090 
<a name="l00091"></a>00091 
<a name="l00092"></a>00092 
<a name="l00094"></a>00094 <span class="comment">//      Change a neuron&#39;s gain</span>
<a name="l00095"></a>00095 <span class="comment">//</span>
<a name="l00096"></a>00096 
<a name="l00097"></a><a class="code" href="class_neuron.html#a3bf7c72a2f28f24e53749aefa0dce3f0">00097</a> <span class="keywordtype">void</span> <a class="code" href="class_neuron.html#a3bf7c72a2f28f24e53749aefa0dce3f0" title="Set a neuron&#39;s gain to a different value.">Neuron::SetNeuronGain</a>(<span class="keywordtype">double</span> dNewGain)
<a name="l00098"></a>00098 {
<a name="l00099"></a>00099     <a class="code" href="class_neuron.html#a94560a022ec198c9114a09a8097a89c0" title="Gain for this neuron.">dGain</a> = dNewGain;
<a name="l00100"></a>00100 };
<a name="l00102"></a>00102 
<a name="l00103"></a>00103 
<a name="l00104"></a>00104 
<a name="l00106"></a>00106 <span class="comment">//     Calculate output from all inputs</span>
<a name="l00107"></a>00107 <span class="comment">//</span>
<a name="l00108"></a>00108 
<a name="l00109"></a><a class="code" href="class_neuron.html#a66460702cb8222e2e9b959634fdc0281">00109</a> <span class="keywordtype">void</span> <a class="code" href="class_neuron.html#a66460702cb8222e2e9b959634fdc0281" title="Combine inputs.">Neuron::CalculateOutput</a>(<a class="code" href="class_neuron.html">Neuron</a> **p_layer)
<a name="l00110"></a>00110 {
<a name="l00111"></a>00111     <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> count;
<a name="l00112"></a>00112 
<a name="l00113"></a>00113     <span class="comment">// Adaptive linear combiner</span>
<a name="l00114"></a>00114     <a class="code" href="class_neuron.html#af3db32b579a42a5c428ceb6ef7365f8c" title="Pure calculated output.">sum</a> = 0.0f;
<a name="l00115"></a>00115     <span class="keywordflow">for</span>(count = 0; count &lt; <a class="code" href="class_neuron.html#a04d04b23fae8548335721a06f5a1a6f0" title="Number of inputs.">inputs</a>; count++)
<a name="l00116"></a>00116         <a class="code" href="class_neuron.html#af3db32b579a42a5c428ceb6ef7365f8c" title="Pure calculated output.">sum</a> += <a class="code" href="class_neuron.html#ad1a0c0ced35f712cc8ace29898154046" title="Weights.">weights</a>[count] * p_layer[count]-&gt;<a class="code" href="class_neuron.html#ab1583b0659eb2189fe0fd20b4af2ddb3" title="Actual output.">output</a>;
<a name="l00117"></a>00117 
<a name="l00118"></a>00118     <a class="code" href="class_neuron.html#ab1583b0659eb2189fe0fd20b4af2ddb3" title="Actual output.">output</a> = <a class="code" href="class_neuron.html#a2f8f0b6b5e8e3996b281ec38735e40ea" title="Sigmoid unsigned transfer.">TransferFunction</a>(<a class="code" href="class_neuron.html#af3db32b579a42a5c428ceb6ef7365f8c" title="Pure calculated output.">sum</a>);
<a name="l00119"></a>00119 };
<a name="l00121"></a>00121 
<a name="l00122"></a>00122 
<a name="l00123"></a>00123 
<a name="l00125"></a>00125 <span class="comment">//      Transfer function for SIGMOID_UNSIGNED</span>
<a name="l00126"></a>00126 <span class="comment">//</span>
<a name="l00127"></a>00127 
<a name="l00128"></a><a class="code" href="class_neuron.html#a2f8f0b6b5e8e3996b281ec38735e40ea">00128</a> <span class="keywordtype">double</span> <a class="code" href="class_neuron.html#a2f8f0b6b5e8e3996b281ec38735e40ea" title="Sigmoid unsigned transfer.">Neuron::TransferFunction</a>(<span class="keywordtype">double</span> input)
<a name="l00129"></a>00129 {
<a name="l00130"></a>00130     <span class="keywordtype">double</span> tf_transfer;
<a name="l00131"></a>00131 
<a name="l00132"></a>00132     <span class="comment">// Sigmoid function</span>
<a name="l00133"></a>00133 <span class="preprocessor">#ifdef USE_TANH</span>
<a name="l00134"></a>00134 <span class="preprocessor"></span>    tf_transfer = (double) ::tanh(input); <span class="comment">// dGain?</span>
<a name="l00135"></a>00135 <span class="preprocessor">#else</span>
<a name="l00136"></a>00136 <span class="preprocessor"></span>    tf_transfer = (double) (1 / (1 + ::exp(-<a class="code" href="class_neuron.html#a94560a022ec198c9114a09a8097a89c0" title="Gain for this neuron.">dGain</a> * input)));
<a name="l00137"></a>00137 <span class="preprocessor">#endif</span>
<a name="l00138"></a>00138 <span class="preprocessor"></span>
<a name="l00139"></a>00139     <span class="keywordflow">return</span>(tf_transfer);
<a name="l00140"></a>00140 };
<a name="l00142"></a>00142 
<a name="l00143"></a>00143 
<a name="l00145"></a>00145 <span class="comment">//     Calculate the EW for output layer</span>
<a name="l00146"></a>00146 <span class="comment">//</span>
<a name="l00147"></a>00147 
<a name="l00148"></a><a class="code" href="class_neuron.html#ac3375bc325a1b84def662961e516c4af">00148</a> <span class="keywordtype">void</span> <a class="code" href="class_neuron.html#ac3375bc325a1b84def662961e516c4af" title="Calculate error weight for outer layer - backprop.">Neuron::CalculateOuterEWBackProp</a>(<span class="keywordtype">double</span> target, <a class="code" href="class_neuron.html">Neuron</a> **p_layer)
<a name="l00149"></a>00149 {
<a name="l00150"></a>00150     <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> count; <span class="comment">// Counter</span>
<a name="l00151"></a>00151 
<a name="l00152"></a>00152     <span class="comment">// Error derivative</span>
<a name="l00153"></a>00153     <a class="code" href="class_neuron.html#afd7da28bcf28a83b95dea4d6b4a38ce0" title="Error derivative.">ea</a> = target - <a class="code" href="class_neuron.html#ab1583b0659eb2189fe0fd20b4af2ddb3" title="Actual output.">output</a>; <span class="comment">// Our error</span>
<a name="l00154"></a>00154 
<a name="l00155"></a>00155     <span class="comment">// Derivative of the SIGMOID function</span>
<a name="l00156"></a>00156 <span class="preprocessor">#ifdef USE_TANH</span>
<a name="l00157"></a>00157 <span class="preprocessor"></span>    <a class="code" href="class_neuron.html#a35050fe1d82011db1336948fb73bab71" title="Rate of error change.">ei</a> = <a class="code" href="class_neuron.html#afd7da28bcf28a83b95dea4d6b4a38ce0" title="Error derivative.">ea</a> * (1.0f - (output * <a class="code" href="class_neuron.html#ab1583b0659eb2189fe0fd20b4af2ddb3" title="Actual output.">output</a>));
<a name="l00158"></a>00158 <span class="preprocessor">#else</span>
<a name="l00159"></a>00159 <span class="preprocessor"></span>    <a class="code" href="class_neuron.html#a35050fe1d82011db1336948fb73bab71" title="Rate of error change.">ei</a> = <a class="code" href="class_neuron.html#afd7da28bcf28a83b95dea4d6b4a38ce0" title="Error derivative.">ea</a> * output * (1.0f - <a class="code" href="class_neuron.html#ab1583b0659eb2189fe0fd20b4af2ddb3" title="Actual output.">output</a>);
<a name="l00160"></a>00160 <span class="preprocessor">#endif</span>
<a name="l00161"></a>00161 <span class="preprocessor"></span>
<a name="l00162"></a>00162     <span class="comment">// Error weight</span>
<a name="l00163"></a>00163     <span class="keywordflow">for</span>(count = 0; count &lt; <a class="code" href="class_neuron.html#a04d04b23fae8548335721a06f5a1a6f0" title="Number of inputs.">inputs</a>; count++)
<a name="l00164"></a>00164         <a class="code" href="class_neuron.html#ab346b4b1b16993ccf1fba04f69622582" title="Error weights for each input.">ew</a>[count] = <a class="code" href="class_neuron.html#a35050fe1d82011db1336948fb73bab71" title="Rate of error change.">ei</a> * p_layer[count]-&gt;output;
<a name="l00165"></a>00165 
<a name="l00166"></a>00166 };
<a name="l00168"></a>00168 
<a name="l00169"></a>00169 
<a name="l00170"></a>00170 
<a name="l00171"></a>00171 
<a name="l00173"></a>00173 <span class="comment">//     Calculate the EW for hidden layers</span>
<a name="l00174"></a>00174 <span class="comment">//</span>
<a name="l00175"></a>00175 
<a name="l00176"></a><a class="code" href="class_neuron.html#ac460565ab559b81402581cdba70d9192">00176</a> <span class="keywordtype">void</span> <a class="code" href="class_neuron.html#ac460565ab559b81402581cdba70d9192" title="Calculate error weight for hidden layer - backprop.">Neuron::CalculateHiddenEWBackProp</a>(<a class="code" href="class_neuron.html">Neuron</a> **p_layer, <a class="code" href="class_neuron.html">Neuron</a> **n_layer, <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> elements)
<a name="l00177"></a>00177 { <span class="comment">// elements is number of neurons in n_layer (next layer)</span>
<a name="l00178"></a>00178     <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> count;
<a name="l00179"></a>00179 
<a name="l00180"></a>00180     <span class="comment">// Calculate EA for this layer by adding</span>
<a name="l00181"></a>00181     <span class="comment">// next layer&#39;s EI * weight for this neuron output</span>
<a name="l00182"></a>00182     <a class="code" href="class_neuron.html#afd7da28bcf28a83b95dea4d6b4a38ce0" title="Error derivative.">ea</a> = 0.0f;
<a name="l00183"></a>00183     <span class="keywordflow">for</span>(count = 0; count &lt; elements; count++)
<a name="l00184"></a>00184         <a class="code" href="class_neuron.html#afd7da28bcf28a83b95dea4d6b4a38ce0" title="Error derivative.">ea</a> += n_layer[count]-&gt;<a class="code" href="class_neuron.html#a35050fe1d82011db1336948fb73bab71" title="Rate of error change.">ei</a> * n_layer[count]-&gt;<a class="code" href="class_neuron.html#ad1a0c0ced35f712cc8ace29898154046" title="Weights.">weights</a>[<span class="keywordtype">id</span>];
<a name="l00185"></a>00185 
<a name="l00186"></a>00186     <span class="comment">// Derivative of the SIGMOID function</span>
<a name="l00187"></a>00187 <span class="preprocessor">#ifdef USE_TANH</span>
<a name="l00188"></a>00188 <span class="preprocessor"></span>    <a class="code" href="class_neuron.html#a35050fe1d82011db1336948fb73bab71" title="Rate of error change.">ei</a> = <a class="code" href="class_neuron.html#afd7da28bcf28a83b95dea4d6b4a38ce0" title="Error derivative.">ea</a> * (1.0f - (<a class="code" href="class_neuron.html#ab1583b0659eb2189fe0fd20b4af2ddb3" title="Actual output.">output</a> * <a class="code" href="class_neuron.html#ab1583b0659eb2189fe0fd20b4af2ddb3" title="Actual output.">output</a>));
<a name="l00189"></a>00189 <span class="preprocessor">#else</span>
<a name="l00190"></a>00190 <span class="preprocessor"></span>    <a class="code" href="class_neuron.html#a35050fe1d82011db1336948fb73bab71" title="Rate of error change.">ei</a> = <a class="code" href="class_neuron.html#afd7da28bcf28a83b95dea4d6b4a38ce0" title="Error derivative.">ea</a> * <a class="code" href="class_neuron.html#ab1583b0659eb2189fe0fd20b4af2ddb3" title="Actual output.">output</a> * (1.0f - <a class="code" href="class_neuron.html#ab1583b0659eb2189fe0fd20b4af2ddb3" title="Actual output.">output</a>);
<a name="l00191"></a>00191 <span class="preprocessor">#endif</span>
<a name="l00192"></a>00192 <span class="preprocessor"></span>
<a name="l00193"></a>00193     <span class="comment">// Now calculate derivative error weight for each input</span>
<a name="l00194"></a>00194     <span class="keywordflow">for</span>(count = 0; count &lt; <a class="code" href="class_neuron.html#a04d04b23fae8548335721a06f5a1a6f0" title="Number of inputs.">inputs</a>; count++)
<a name="l00195"></a>00195         <a class="code" href="class_neuron.html#ab346b4b1b16993ccf1fba04f69622582" title="Error weights for each input.">ew</a>[count] = <a class="code" href="class_neuron.html#a35050fe1d82011db1336948fb73bab71" title="Rate of error change.">ei</a> * p_layer[count]-&gt;<a class="code" href="class_neuron.html#ab1583b0659eb2189fe0fd20b4af2ddb3" title="Actual output.">output</a>;
<a name="l00196"></a>00196 };
<a name="l00198"></a>00198 
<a name="l00199"></a>00199 
<a name="l00200"></a>00200 
<a name="l00202"></a>00202 <span class="comment">//  Make the neuron learn by adjusting weights</span>
<a name="l00203"></a>00203 <span class="comment">//</span>
<a name="l00204"></a>00204 <span class="comment">//      Note that when doing straight back-prop, we use &quot;pattern&quot; learning, </span>
<a name="l00205"></a>00205 <span class="comment">//      i.e. we adjust the weights after each pattern is fed forward and the error calculated.</span>
<a name="l00206"></a>00206 <span class="comment">//</span>
<a name="l00207"></a>00207 
<a name="l00208"></a><a class="code" href="class_neuron.html#a7c28c5e0148a8556b773f056a22d2997">00208</a> <span class="keywordtype">void</span> <a class="code" href="class_neuron.html#a7c28c5e0148a8556b773f056a22d2997" title="Adjust all neuron weights - backprop.">Neuron::AdjustWeightsBackProp</a>(<a class="code" href="class_neuron.html">Neuron</a> **p_layer, <span class="keywordtype">double</span> delta)
<a name="l00209"></a>00209 {
<a name="l00210"></a>00210     <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> count;
<a name="l00211"></a>00211     <span class="keywordtype">double</span> adjust;
<a name="l00212"></a>00212 
<a name="l00213"></a>00213     <span class="keywordflow">for</span>(count = 0; count &lt; <a class="code" href="class_neuron.html#a04d04b23fae8548335721a06f5a1a6f0" title="Number of inputs.">inputs</a>; count++)
<a name="l00214"></a>00214     { <span class="comment">// Calculated from formulas plus a little extra oomph</span>
<a name="l00215"></a>00215         adjust = (delta * <a class="code" href="class_neuron.html#ab346b4b1b16993ccf1fba04f69622582" title="Error weights for each input.">ew</a>[count] * p_layer[count]-&gt;<a class="code" href="class_neuron.html#ab1583b0659eb2189fe0fd20b4af2ddb3" title="Actual output.">output</a>) + (<a class="code" href="class_neuron.html#a4fb2325296966ff19b1a18e9f39e6b72" title="Net we&#39;re a part of.">pNeuralNet</a>-&gt;<a class="code" href="class_neural_net.html#ae2abb290d0c972e07df4a6b8ba37a910" title="Momentum factor.">momentum</a> * <a class="code" href="class_neuron.html#a789e0e384caf1cbfb4297acff8ac8fc8" title="Previous change to weight delta.">prev_adj</a>[count]);
<a name="l00216"></a>00216 <span class="preprocessor">#ifdef TANH</span>
<a name="l00217"></a>00217 <span class="preprocessor"></span>        <a class="code" href="class_neuron.html#ad1a0c0ced35f712cc8ace29898154046" title="Weights.">weights</a>[count] -= adjust; <span class="comment">// ??</span>
<a name="l00218"></a>00218 <span class="preprocessor">#else</span>
<a name="l00219"></a>00219 <span class="preprocessor"></span>        <a class="code" href="class_neuron.html#ad1a0c0ced35f712cc8ace29898154046" title="Weights.">weights</a>[count] += adjust;
<a name="l00220"></a>00220 <span class="preprocessor">#endif</span>
<a name="l00221"></a>00221 <span class="preprocessor"></span>        <a class="code" href="class_neuron.html#a789e0e384caf1cbfb4297acff8ac8fc8" title="Previous change to weight delta.">prev_adj</a>[count] = adjust;
<a name="l00222"></a>00222     };
<a name="l00223"></a>00223 };
<a name="l00225"></a>00225 
<a name="l00226"></a>00226 
<a name="l00227"></a>00227 
<a name="l00229"></a>00229 <span class="comment">//     Calculate the EW for output layer</span>
<a name="l00230"></a>00230 <span class="comment">//</span>
<a name="l00231"></a>00231 
<a name="l00232"></a><a class="code" href="class_neuron.html#a91aa5034ce15b1e434705121a3169df6">00232</a> <span class="keywordtype">void</span> <a class="code" href="class_neuron.html#a91aa5034ce15b1e434705121a3169df6" title="Calculate error weight for outer layer - RProp.">Neuron::CalculateOuterEWRProp</a>(<span class="keywordtype">double</span> target, <a class="code" href="class_neuron.html">Neuron</a> **p_layer)
<a name="l00233"></a>00233 {
<a name="l00234"></a>00234     <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> count; <span class="comment">// Counter</span>
<a name="l00235"></a>00235 
<a name="l00236"></a>00236     <span class="comment">// Error derivative</span>
<a name="l00237"></a>00237     <a class="code" href="class_neuron.html#afd7da28bcf28a83b95dea4d6b4a38ce0" title="Error derivative.">ea</a> = target - <a class="code" href="class_neuron.html#ab1583b0659eb2189fe0fd20b4af2ddb3" title="Actual output.">output</a>; <span class="comment">// Our error</span>
<a name="l00238"></a>00238 
<a name="l00239"></a>00239     <span class="comment">// Derivative of the SIGMOID function</span>
<a name="l00240"></a>00240 <span class="preprocessor">#ifdef USE_TANH</span>
<a name="l00241"></a>00241 <span class="preprocessor"></span>    <a class="code" href="class_neuron.html#a35050fe1d82011db1336948fb73bab71" title="Rate of error change.">ei</a> = <a class="code" href="class_neuron.html#afd7da28bcf28a83b95dea4d6b4a38ce0" title="Error derivative.">ea</a> * (1.0f - (output * <a class="code" href="class_neuron.html#ab1583b0659eb2189fe0fd20b4af2ddb3" title="Actual output.">output</a>));
<a name="l00242"></a>00242 <span class="preprocessor">#else</span>
<a name="l00243"></a>00243 <span class="preprocessor"></span>    <a class="code" href="class_neuron.html#a35050fe1d82011db1336948fb73bab71" title="Rate of error change.">ei</a> = <a class="code" href="class_neuron.html#afd7da28bcf28a83b95dea4d6b4a38ce0" title="Error derivative.">ea</a> * output * (1.0f - <a class="code" href="class_neuron.html#ab1583b0659eb2189fe0fd20b4af2ddb3" title="Actual output.">output</a>);
<a name="l00244"></a>00244 <span class="preprocessor">#endif</span>
<a name="l00245"></a>00245 <span class="preprocessor"></span>
<a name="l00246"></a>00246     <span class="comment">// Error weight</span>
<a name="l00247"></a>00247     <span class="comment">// NOTE: RProp modification - sum error weights</span>
<a name="l00248"></a>00248     <span class="keywordflow">for</span>(count = 0; count &lt; <a class="code" href="class_neuron.html#a04d04b23fae8548335721a06f5a1a6f0" title="Number of inputs.">inputs</a>; count++)
<a name="l00249"></a>00249         <a class="code" href="class_neuron.html#ab346b4b1b16993ccf1fba04f69622582" title="Error weights for each input.">ew</a>[count] -= <a class="code" href="class_neuron.html#a35050fe1d82011db1336948fb73bab71" title="Rate of error change.">ei</a> * p_layer[count]-&gt;output;
<a name="l00250"></a>00250 
<a name="l00251"></a>00251 };
<a name="l00253"></a>00253 
<a name="l00254"></a>00254 
<a name="l00255"></a>00255 
<a name="l00256"></a>00256 
<a name="l00258"></a>00258 <span class="comment">//     Calculate the EW for hidden layers</span>
<a name="l00259"></a>00259 <span class="comment">//</span>
<a name="l00260"></a>00260 
<a name="l00261"></a><a class="code" href="class_neuron.html#ac54196b8e8a14ee092c13bf624cea925">00261</a> <span class="keywordtype">void</span> <a class="code" href="class_neuron.html#ac54196b8e8a14ee092c13bf624cea925" title="Calculate error weight for hidden layer - RProp.">Neuron::CalculateHiddenEWRProp</a>(<a class="code" href="class_neuron.html">Neuron</a> **p_layer, <a class="code" href="class_neuron.html">Neuron</a> **n_layer, <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> elements)
<a name="l00262"></a>00262 { <span class="comment">// elements is number of neurons in n_layer (next layer)</span>
<a name="l00263"></a>00263     <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> count;
<a name="l00264"></a>00264 
<a name="l00265"></a>00265     <span class="comment">// Calculate EA for this layer by adding</span>
<a name="l00266"></a>00266     <span class="comment">// next layer&#39;s EI * weight for this neuron output</span>
<a name="l00267"></a>00267     <a class="code" href="class_neuron.html#afd7da28bcf28a83b95dea4d6b4a38ce0" title="Error derivative.">ea</a> = 0.0f;
<a name="l00268"></a>00268     <span class="keywordflow">for</span>(count = 0; count &lt; elements; count++)
<a name="l00269"></a>00269         <a class="code" href="class_neuron.html#afd7da28bcf28a83b95dea4d6b4a38ce0" title="Error derivative.">ea</a> += n_layer[count]-&gt;<a class="code" href="class_neuron.html#a35050fe1d82011db1336948fb73bab71" title="Rate of error change.">ei</a> * n_layer[count]-&gt;<a class="code" href="class_neuron.html#ad1a0c0ced35f712cc8ace29898154046" title="Weights.">weights</a>[<span class="keywordtype">id</span>];
<a name="l00270"></a>00270 
<a name="l00271"></a>00271     <span class="comment">// Derivative of the SIGMOID function</span>
<a name="l00272"></a>00272 <span class="preprocessor">#ifdef USE_TANH</span>
<a name="l00273"></a>00273 <span class="preprocessor"></span>    <a class="code" href="class_neuron.html#a35050fe1d82011db1336948fb73bab71" title="Rate of error change.">ei</a> = <a class="code" href="class_neuron.html#afd7da28bcf28a83b95dea4d6b4a38ce0" title="Error derivative.">ea</a> * (1.0f - (<a class="code" href="class_neuron.html#ab1583b0659eb2189fe0fd20b4af2ddb3" title="Actual output.">output</a> * <a class="code" href="class_neuron.html#ab1583b0659eb2189fe0fd20b4af2ddb3" title="Actual output.">output</a>));
<a name="l00274"></a>00274 <span class="preprocessor">#else</span>
<a name="l00275"></a>00275 <span class="preprocessor"></span>    <a class="code" href="class_neuron.html#a35050fe1d82011db1336948fb73bab71" title="Rate of error change.">ei</a> = <a class="code" href="class_neuron.html#afd7da28bcf28a83b95dea4d6b4a38ce0" title="Error derivative.">ea</a> * <a class="code" href="class_neuron.html#ab1583b0659eb2189fe0fd20b4af2ddb3" title="Actual output.">output</a> * (1.0f - <a class="code" href="class_neuron.html#ab1583b0659eb2189fe0fd20b4af2ddb3" title="Actual output.">output</a>);
<a name="l00276"></a>00276 <span class="preprocessor">#endif</span>
<a name="l00277"></a>00277 <span class="preprocessor"></span>
<a name="l00278"></a>00278     <span class="comment">// Now calculate derivative error weight for each input</span>
<a name="l00279"></a>00279     <span class="comment">// NOTE: RProp modification - sum error weights</span>
<a name="l00280"></a>00280     <span class="keywordflow">for</span>(count = 0; count &lt; <a class="code" href="class_neuron.html#a04d04b23fae8548335721a06f5a1a6f0" title="Number of inputs.">inputs</a>; count++)
<a name="l00281"></a>00281         <a class="code" href="class_neuron.html#ab346b4b1b16993ccf1fba04f69622582" title="Error weights for each input.">ew</a>[count] -= <a class="code" href="class_neuron.html#a35050fe1d82011db1336948fb73bab71" title="Rate of error change.">ei</a> * p_layer[count]-&gt;<a class="code" href="class_neuron.html#ab1583b0659eb2189fe0fd20b4af2ddb3" title="Actual output.">output</a>;
<a name="l00282"></a>00282 };
<a name="l00284"></a>00284 
<a name="l00285"></a>00285 
<a name="l00286"></a>00286 
<a name="l00288"></a>00288 <span class="comment">//  Make the neuron learn by adjusting weights, </span>
<a name="l00289"></a>00289 <span class="comment">//      using the RPROP (Resilient Backpropagation) algorithm</span>
<a name="l00290"></a>00290 <span class="comment">//</span>
<a name="l00291"></a>00291 <span class="comment">//      Note that when use Rprop, we use &quot;epoch&quot; or &quot;batch&quot; learning, </span>
<a name="l00292"></a>00292 <span class="comment">//      i.e. we adjust the weights after all patterns in the set are calculated.</span>
<a name="l00293"></a>00293 <span class="comment">//</span>
<a name="l00294"></a>00294 
<a name="l00295"></a><a class="code" href="class_neuron.html#a0f72b892161b6571e9cbc8a5b416f9a9">00295</a> <span class="keywordtype">void</span> <a class="code" href="class_neuron.html#a0f72b892161b6571e9cbc8a5b416f9a9" title="Adjust all neuron weights - RProp.">Neuron::AdjustWeightsRProp</a>(<a class="code" href="class_neuron.html">Neuron</a> **p_layer)
<a name="l00296"></a>00296 {
<a name="l00297"></a>00297     <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> count;
<a name="l00298"></a>00298     <span class="keywordtype">double</span> dSign;
<a name="l00299"></a>00299 
<a name="l00300"></a>00300     <span class="keywordflow">for</span>(count = 0; count &lt; <a class="code" href="class_neuron.html#a04d04b23fae8548335721a06f5a1a6f0" title="Number of inputs.">inputs</a>; count++)
<a name="l00301"></a>00301     { <span class="comment">// RPROP adjustment.  Note that in normal &quot;batch&quot; training</span>
<a name="l00302"></a>00302         <span class="comment">// we would divide the accumulated error by the number of patterns. </span>
<a name="l00303"></a>00303         <span class="comment">// However, RProp is only interested in the sign, so this isn&#39;t necessary.</span>
<a name="l00304"></a>00304         dSign = <a class="code" href="class_neuron.html#aeddb292f243cf9fbb400459d0b3adb30" title="Return -1, +1, or 0.">GetSign</a>(<a class="code" href="class_neuron.html#ab346b4b1b16993ccf1fba04f69622582" title="Error weights for each input.">ew</a>[count] * <a class="code" href="class_neuron.html#a0a01e4454838f363f352bcf2315960fe" title="Previous error weight.">prev_ew</a>[count]);
<a name="l00305"></a>00305         <span class="keywordflow">if</span> (dSign &gt; 0) <span class="comment">// Error weight sign changed to positive</span>
<a name="l00306"></a>00306         {
<a name="l00307"></a>00307             <a class="code" href="class_neuron.html#a789e0e384caf1cbfb4297acff8ac8fc8" title="Previous change to weight delta.">prev_adj</a>[count] *= <a class="code" href="_neuron_8h.html#ae9cb8acc4a44ed6d1109e093a4ffa574">N_PLUS</a>;
<a name="l00308"></a>00308             <span class="keywordflow">if</span> (<a class="code" href="class_neuron.html#a789e0e384caf1cbfb4297acff8ac8fc8" title="Previous change to weight delta.">prev_adj</a>[count] &gt; <a class="code" href="_neuron_8h.html#a0909f9743b77b5e83d3e8e1d61989b10">N_MAX</a>)
<a name="l00309"></a>00309                 <a class="code" href="class_neuron.html#a789e0e384caf1cbfb4297acff8ac8fc8" title="Previous change to weight delta.">prev_adj</a>[count] = <a class="code" href="_neuron_8h.html#a0909f9743b77b5e83d3e8e1d61989b10">N_MAX</a>;
<a name="l00310"></a>00310             <span class="comment">// Save our change in weight size</span>
<a name="l00311"></a>00311             <a class="code" href="class_neuron.html#a6c1f44d16cb090c34ee5d11f6dd8e215" title="The actual previous change to the weight.">delta_weight</a>[count] = -(<a class="code" href="class_neuron.html#aeddb292f243cf9fbb400459d0b3adb30" title="Return -1, +1, or 0.">GetSign</a>(<a class="code" href="class_neuron.html#ab346b4b1b16993ccf1fba04f69622582" title="Error weights for each input.">ew</a>[count])) * <a class="code" href="class_neuron.html#a789e0e384caf1cbfb4297acff8ac8fc8" title="Previous change to weight delta.">prev_adj</a>[count];
<a name="l00312"></a>00312             <a class="code" href="class_neuron.html#ad1a0c0ced35f712cc8ace29898154046" title="Weights.">weights</a>[count] += <a class="code" href="class_neuron.html#a6c1f44d16cb090c34ee5d11f6dd8e215" title="The actual previous change to the weight.">delta_weight</a>[count];
<a name="l00313"></a>00313             <a class="code" href="class_neuron.html#a0a01e4454838f363f352bcf2315960fe" title="Previous error weight.">prev_ew</a>[count] = <a class="code" href="class_neuron.html#ab346b4b1b16993ccf1fba04f69622582" title="Error weights for each input.">ew</a>[count];
<a name="l00314"></a>00314         }
<a name="l00315"></a>00315         <span class="keywordflow">else</span>
<a name="l00316"></a>00316         {
<a name="l00317"></a>00317             <span class="keywordflow">if</span> (dSign &lt; 0) <span class="comment">// Error weight sign change to negative</span>
<a name="l00318"></a>00318             {
<a name="l00319"></a>00319                 <a class="code" href="class_neuron.html#a789e0e384caf1cbfb4297acff8ac8fc8" title="Previous change to weight delta.">prev_adj</a>[count] *= <a class="code" href="_neuron_8h.html#a93888d2bee8f326f2d312cb3702480d4">N_MINUS</a>;
<a name="l00320"></a>00320                 <span class="keywordflow">if</span> (<a class="code" href="class_neuron.html#a789e0e384caf1cbfb4297acff8ac8fc8" title="Previous change to weight delta.">prev_adj</a>[count] &lt; <a class="code" href="_neuron_8h.html#a5cba66cdd527963f919c718c8cb160f3">N_MIN</a>)
<a name="l00321"></a>00321                     <a class="code" href="class_neuron.html#a789e0e384caf1cbfb4297acff8ac8fc8" title="Previous change to weight delta.">prev_adj</a>[count] = <a class="code" href="_neuron_8h.html#a5cba66cdd527963f919c718c8cb160f3">N_MIN</a>;
<a name="l00322"></a>00322                 <span class="comment">// Weight backtracking added from paper by Christian Igel and Michael Husken</span>
<a name="l00323"></a>00323                 <span class="comment">// NOTE, I&#39;m not absolutley sure that the batch error is being computed correctly.</span>
<a name="l00324"></a>00324                 <span class="comment">//               If it isn&#39;t, this code may &quot;hide&quot; that fact by correcting incorrect adjustments.</span>
<a name="l00325"></a>00325                 <span class="comment">//       The effect is that the training may be slower than it otherwise would be.</span>
<a name="l00326"></a>00326                 <span class="keywordflow">if</span> (<a class="code" href="class_neuron.html#a4fb2325296966ff19b1a18e9f39e6b72" title="Net we&#39;re a part of.">pNeuralNet</a>-&gt;<a class="code" href="class_neural_net.html#a3d8aa2fd8788831b334b8fbf5cec26b4" title="Total error.">total_error</a> &gt; <a class="code" href="class_neuron.html#a4fb2325296966ff19b1a18e9f39e6b72" title="Net we&#39;re a part of.">pNeuralNet</a>-&gt;<a class="code" href="class_neural_net.html#abda96359ca1b9a39e6202b23d873c9ec" title="Used for RProp weight backtracking.">prev_total_error</a>)
<a name="l00327"></a>00327                     <a class="code" href="class_neuron.html#ad1a0c0ced35f712cc8ace29898154046" title="Weights.">weights</a>[count] -= <a class="code" href="class_neuron.html#a6c1f44d16cb090c34ee5d11f6dd8e215" title="The actual previous change to the weight.">delta_weight</a>[count];
<a name="l00328"></a>00328                 <a class="code" href="class_neuron.html#a0a01e4454838f363f352bcf2315960fe" title="Previous error weight.">prev_ew</a>[count] = 0.0f;
<a name="l00329"></a>00329             }
<a name="l00330"></a>00330             <span class="keywordflow">else</span> <span class="comment">// No sign change in error weight</span>
<a name="l00331"></a>00331                 <a class="code" href="class_neuron.html#a6c1f44d16cb090c34ee5d11f6dd8e215" title="The actual previous change to the weight.">delta_weight</a>[count] = -(<a class="code" href="class_neuron.html#aeddb292f243cf9fbb400459d0b3adb30" title="Return -1, +1, or 0.">GetSign</a>(<a class="code" href="class_neuron.html#ab346b4b1b16993ccf1fba04f69622582" title="Error weights for each input.">ew</a>[count])) * <a class="code" href="class_neuron.html#a789e0e384caf1cbfb4297acff8ac8fc8" title="Previous change to weight delta.">prev_adj</a>[count];
<a name="l00332"></a>00332             <a class="code" href="class_neuron.html#ad1a0c0ced35f712cc8ace29898154046" title="Weights.">weights</a>[count] += <a class="code" href="class_neuron.html#a6c1f44d16cb090c34ee5d11f6dd8e215" title="The actual previous change to the weight.">delta_weight</a>[count];
<a name="l00333"></a>00333             <a class="code" href="class_neuron.html#a0a01e4454838f363f352bcf2315960fe" title="Previous error weight.">prev_ew</a>[count] = <a class="code" href="class_neuron.html#ab346b4b1b16993ccf1fba04f69622582" title="Error weights for each input.">ew</a>[count];
<a name="l00334"></a>00334         };
<a name="l00335"></a>00335         <a class="code" href="class_neuron.html#ab346b4b1b16993ccf1fba04f69622582" title="Error weights for each input.">ew</a>[count] = 0.0f; <span class="comment">// Prepare for next batch</span>
<a name="l00336"></a>00336     };
<a name="l00337"></a>00337 };
<a name="l00339"></a>00339 
<a name="l00340"></a>00340 
<a name="l00342"></a>00342 <span class="comment">//  Get an input and scale it in.  </span>
<a name="l00343"></a>00343 <span class="comment">//      This is only used for the input layer when solving a problem. </span>
<a name="l00344"></a>00344 <span class="comment">//      Training sets are prescaled.</span>
<a name="l00345"></a>00345 <span class="comment">//</span>
<a name="l00346"></a>00346 
<a name="l00347"></a><a class="code" href="class_neuron.html#a11bfccb32d07c0a9f048992e36f99f05">00347</a> <span class="keywordtype">void</span> <a class="code" href="class_neuron.html#a11bfccb32d07c0a9f048992e36f99f05" title="Scale in a value and set output to it.">Neuron::ScaleIn</a>(<span class="keywordtype">double</span> dTempInput)
<a name="l00348"></a>00348 {
<a name="l00349"></a>00349     <span class="keywordtype">double</span> dWork;
<a name="l00350"></a>00350 
<a name="l00351"></a>00351     <a class="code" href="class_neuron.html#ab4771a78f565a3c8d9867c465227f946" title="Input prior to scaling if input neuron.">dInput</a> = dTempInput;
<a name="l00352"></a>00352 
<a name="l00353"></a>00353     dWork = <a class="code" href="class_neuron.html#ab4771a78f565a3c8d9867c465227f946" title="Input prior to scaling if input neuron.">dInput</a> - <a class="code" href="class_neuron.html#a4fb2325296966ff19b1a18e9f39e6b72" title="Net we&#39;re a part of.">pNeuralNet</a>-&gt;<a class="code" href="class_neural_net.html#ab731e89f294639ee1de018a02204d47e">vInputMean</a>[<a class="code" href="class_neuron.html#afac66e86f21b7c989f3bbdd341fa3764" title="Our layer.">id</a>];
<a name="l00354"></a>00354     dWork /= <a class="code" href="class_neuron.html#a4fb2325296966ff19b1a18e9f39e6b72" title="Net we&#39;re a part of.">pNeuralNet</a>-&gt;<a class="code" href="class_neural_net.html#abcbc27b95edbba0f3a0b0be9caeea104" title="Save the standard deviation for all outputs.">vInputStdDev</a>[<a class="code" href="class_neuron.html#afac66e86f21b7c989f3bbdd341fa3764" title="Our layer.">id</a>];
<a name="l00355"></a>00355     dWork += 3; <span class="comment">// So make them all positive</span>
<a name="l00356"></a>00356     dWork /= 2; <span class="comment">// and between 0 and 3</span>
<a name="l00357"></a>00357     <span class="keywordflow">if</span> (dWork &lt; 0)
<a name="l00358"></a>00358         dWork = 0;
<a name="l00359"></a>00359 
<a name="l00360"></a>00360     <a class="code" href="class_neuron.html#ab1583b0659eb2189fe0fd20b4af2ddb3" title="Actual output.">output</a> = dWork;
<a name="l00361"></a>00361 };
<a name="l00363"></a>00363 
<a name="l00364"></a>00364 
<a name="l00366"></a>00366 <span class="comment">//     Scale the output and return it to the caller.  </span>
<a name="l00367"></a>00367 <span class="comment">//     This is only used for the output layer.</span>
<a name="l00368"></a>00368 <span class="comment">//</span>
<a name="l00369"></a>00369 
<a name="l00370"></a><a class="code" href="class_neuron.html#ac44a9a32d84d9b961e51f2c09245333a">00370</a> <span class="keywordtype">double</span> <a class="code" href="class_neuron.html#ac44a9a32d84d9b961e51f2c09245333a" title="Scale what&#39;s in output and return it.">Neuron::ScaleOut</a>()
<a name="l00371"></a>00371 {
<a name="l00372"></a>00372     <span class="keywordtype">double</span> dWork;
<a name="l00373"></a>00373     <span class="keywordtype">double</span> dMean;
<a name="l00374"></a>00374     <span class="keywordtype">double</span> dStdDev;
<a name="l00375"></a>00375 
<a name="l00376"></a>00376     dMean = <a class="code" href="class_neuron.html#a4fb2325296966ff19b1a18e9f39e6b72" title="Net we&#39;re a part of.">pNeuralNet</a>-&gt;<a class="code" href="class_neural_net.html#a87b0d2e664dda7def01e437cd1c69028" title="Save the mean for all outputs.">vOutputMean</a>[<a class="code" href="class_neuron.html#afac66e86f21b7c989f3bbdd341fa3764" title="Our layer.">id</a>];
<a name="l00377"></a>00377     dStdDev = <a class="code" href="class_neuron.html#a4fb2325296966ff19b1a18e9f39e6b72" title="Net we&#39;re a part of.">pNeuralNet</a>-&gt;<a class="code" href="class_neural_net.html#af80ee309cb980881a48a2b06ec8ec94c" title="Save the standard deviation for all outputs.">vOutputStdDev</a>[<a class="code" href="class_neuron.html#afac66e86f21b7c989f3bbdd341fa3764" title="Our layer.">id</a>];
<a name="l00378"></a>00378     dWork = <a class="code" href="class_neuron.html#ab1583b0659eb2189fe0fd20b4af2ddb3" title="Actual output.">output</a> * 6;
<a name="l00379"></a>00379     dWork -= 3;
<a name="l00380"></a>00380     dWork *= dStdDev;
<a name="l00381"></a>00381     dWork += dMean;
<a name="l00382"></a>00382 
<a name="l00383"></a>00383     <span class="keywordflow">return</span>(dWork);
<a name="l00384"></a>00384 };
<a name="l00386"></a>00386 
<a name="l00387"></a>00387 
<a name="l00389"></a>00389 <span class="comment">//     Set the neuron label</span>
<a name="l00390"></a>00390 <span class="comment">//     </span>
<a name="l00391"></a>00391 <span class="comment">//</span>
<a name="l00392"></a>00392 
<a name="l00393"></a><a class="code" href="class_neuron.html#a6724c015e67ed24f2a51437dde1167be">00393</a> <span class="keywordtype">bool</span> <a class="code" href="class_neuron.html#a6724c015e67ed24f2a51437dde1167be" title="Allocate the label string and set it.">Neuron::SetNeuronLabel</a>(<span class="keyword">const</span> <span class="keywordtype">char</span> * cNewLabel)
<a name="l00394"></a>00394 {
<a name="l00395"></a>00395     <a class="code" href="class_neuron.html#a581bb535096e2fbe1b965eaa33feaf25" title="For input and output neurons, the name.">cLabel</a> = cNewLabel;
<a name="l00396"></a>00396     <span class="keywordflow">return</span>(<span class="keyword">true</span>);
<a name="l00397"></a>00397 };
<a name="l00399"></a>00399 
<a name="l00400"></a>00400 
<a name="l00401"></a>00401 
<a name="l00402"></a>00402 
<a name="l00404"></a>00404 <span class="comment">//              Get the label</span>
<a name="l00405"></a>00405 <span class="comment">//     </span>
<a name="l00406"></a>00406 <span class="comment">//</span>
<a name="l00407"></a>00407 
<a name="l00408"></a><a class="code" href="class_neuron.html#ab57fb90eed690cfb0ee06a822a4882fe">00408</a> <span class="keyword">const</span> <span class="keywordtype">char</span> * <a class="code" href="class_neuron.html#ab57fb90eed690cfb0ee06a822a4882fe" title="Get the label.">Neuron::GetNeuronLabel</a>()
<a name="l00409"></a>00409 {
<a name="l00410"></a>00410     <span class="keywordflow">return</span>(<a class="code" href="class_neuron.html#a581bb535096e2fbe1b965eaa33feaf25" title="For input and output neurons, the name.">cLabel</a>.c_str());
<a name="l00411"></a>00411 };
<a name="l00413"></a>00413 
<a name="l00414"></a>00414 
<a name="l00416"></a>00416 <span class="comment">//    Return the sign of a value )(-1, +1, 0)</span>
<a name="l00417"></a>00417 <span class="comment">//</span>
<a name="l00418"></a>00418 
<a name="l00419"></a><a class="code" href="class_neuron.html#aeddb292f243cf9fbb400459d0b3adb30">00419</a> <span class="keywordtype">double</span> <a class="code" href="class_neuron.html#aeddb292f243cf9fbb400459d0b3adb30" title="Return -1, +1, or 0.">Neuron::GetSign</a>(<span class="keywordtype">double</span> dValue)
<a name="l00420"></a>00420 {
<a name="l00421"></a>00421     <span class="keywordflow">if</span> (dValue &gt; 0)
<a name="l00422"></a>00422         <span class="keywordflow">return</span> 1.0f;
<a name="l00423"></a>00423     <span class="keywordflow">if</span> (dValue &lt; 0)
<a name="l00424"></a>00424         <span class="keywordflow">return</span> -1.0f;
<a name="l00425"></a>00425     <span class="keywordflow">return</span> 0.0f;
<a name="l00426"></a>00426 };
<a name="l00427"></a>00427 
<a name="l00428"></a>00428 
<a name="l00430"></a>00430 <span class="comment">//    Get the time in ms</span>
<a name="l00431"></a>00431 <span class="comment">//</span>
<a name="l00432"></a>00432 
<a name="l00433"></a><a class="code" href="_neuron_8cpp.html#ad6569deb372fc209034052f030e91ff4">00433</a> <span class="keywordtype">unsigned</span> <span class="keywordtype">long</span> <a class="code" href="_neuron_8cpp.html#ad6569deb372fc209034052f030e91ff4">GetMilliseconds</a>()
<a name="l00434"></a>00434 {
<a name="l00435"></a>00435     <span class="keyword">struct </span>timeval curr;
<a name="l00436"></a>00436 
<a name="l00437"></a>00437     <span class="keywordtype">unsigned</span> <span class="keywordtype">long</span> mtime;
<a name="l00438"></a>00438 
<a name="l00439"></a>00439     ::gettimeofday(&amp;curr, NULL);
<a name="l00440"></a>00440     mtime = (((curr.tv_sec) * 1000) + (curr.tv_usec / 1000.0)) + 0.5;
<a name="l00441"></a>00441 
<a name="l00442"></a>00442     <span class="keywordflow">return</span>(mtime);
<a name="l00443"></a>00443 }
<a name="l00444"></a>00444 
<a name="l00446"></a>00446 <span class="comment">//     End of: NEURON.CPP</span>
<a name="l00448"></a>00448 <span class="comment"></span>
<a name="l00449"></a>00449 
</pre></div></div><!-- contents -->
</div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
<a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(0)"><span class="SelectionMark">&#160;</span>All</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(1)"><span class="SelectionMark">&#160;</span>Classes</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(2)"><span class="SelectionMark">&#160;</span>Files</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(3)"><span class="SelectionMark">&#160;</span>Functions</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(4)"><span class="SelectionMark">&#160;</span>Variables</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(5)"><span class="SelectionMark">&#160;</span>Typedefs</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(6)"><span class="SelectionMark">&#160;</span>Enumerator</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(7)"><span class="SelectionMark">&#160;</span>Friends</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(8)"><span class="SelectionMark">&#160;</span>Defines</a></div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

  <div id="nav-path" class="navpath">
    <ul>
      <li class="navelem"><a class="el" href="_neuron_8cpp.html">Neuron.cpp</a>      </li>

    <li class="footer">Generated on Sun Feb 24 2013 14:27:42 for nnengine by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.7.6.1 </li>
   </ul>
 </div>


</body>
</html>
